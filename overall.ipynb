{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from numpy import mean, std\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import export_graphviz\n",
    "from scipy.stats import chi2_contingency, sem, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, RepeatedStratifiedKFold, StratifiedKFold,cross_val_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, precision_score, recall_score, confusion_matrix, auc, mean_squared_error, r2_score, classification_report\n",
    "from sklearn.preprocessing import label_binarize, scale\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bereinigte Daten einholen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindung zur SQLite-Datenbank herstellen\n",
    "conn = sqlite3.connect('neue_datenbank_numeric.db')\n",
    "\n",
    "# SQL-Abfrage ausführen und Ergebnis in ein Pandas-Dataframe laden\n",
    "df = pd.read_sql(\"SELECT * FROM neue_tabelle_mit_allen_numerischen_Daten\", conn)\n",
    "\n",
    "# Verbindung schließen\n",
    "conn.close()\n",
    "\n",
    "df_dropped = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korrelation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrelaitonsmatrix erstellt und in corr_matrix gespeichert => enthält Korrleationskoeffizienten zwischen allen möglichen Paaren\n",
    "corr_matrix = df_dropped.corr()\n",
    "\n",
    "# stack() wandelt Matrix in Series um, bei der jedes Element ein Paar von Spaltennamen und der Korrelationskoeffizient zwischen diesen Spalten ist\n",
    "# [abs(corr_matrix) > 0.9] reduziert die Werte auf nur Werte mit einem Wert über 0.9\n",
    "high_corr_pairs = corr_matrix.stack()[abs(corr_matrix.stack()) > 0.9]\n",
    "\n",
    "# Indizes der Serie werden zu Spaltennamen des Dataframe \n",
    "high_corr_pairs = high_corr_pairs.reset_index()\n",
    "\n",
    "# Spaltennamen des DataFrames umbenannt für bessere Lesbarkeit\n",
    "high_corr_pairs.columns = ['Column 1', 'Column 2', 'Correlation']\n",
    "\n",
    "print(high_corr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maske für oberes Dreieck erstellen\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Erstellen von Heatmap mit Threshold\n",
    "plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(corr_matrix[(corr_matrix >= 0.3) | (corr_matrix <= -0.3)],\n",
    "            cmap='coolwarm', annot=True, fmt='.2f', mask=mask)\n",
    "\n",
    "# Anpassen der Ausgabe\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style({'font.family': 'serif', 'fontcolor': 'black'})\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # erstelle ein Dataframe für die Ergebnis von Chi2\n",
    "chi2_results_df = pd.DataFrame(columns=['Column 1', 'Column 2', 'Chi-Squared', 'P-Value'])\n",
    "\n",
    "# iteriert über jede Spalte des Dataframes\n",
    "for col in df_dropped.columns:\n",
    "    comparison_col = col\n",
    "\n",
    "    # iteriert über jede Spalte des Dataframes\n",
    "    for col in df_dropped.columns:\n",
    "\n",
    "        # überspringt den Schritt, wenn die Spalten die gleichen sind\n",
    "        if col == comparison_col:\n",
    "            continue\n",
    "\n",
    "        # erstellt eine Kontingenztabelle\n",
    "        contingency_table = pd.crosstab(df_dropped[comparison_col], df_dropped[col])\n",
    "\n",
    "        # führt chi2 aus und printed das Ergebnis\n",
    "        chi2, pval, dof, expected = chi2_contingency(contingency_table)\n",
    "                    #print(f\\Chi-squared test for columns '{comparison_col}' and '{col}': chi2={chi2}, pval={pval}\\)\n",
    "        new_row = {'Column 1': comparison_col, 'Column 2': col, 'Chi-Squared': chi2, 'P-Value': pval}\n",
    "        chi2_results_df = pd.concat([chi2_results_df, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
    "\n",
    "    print(chi2_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivotiere chi2_results_df, um eine Matrix zu erstellen\n",
    "heatmap_data = chi2_results_df.pivot(index='Column 1', columns='Column 2', values='P-Value')\n",
    "\n",
    "# Größe der Ausgabe\n",
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "# Erzeugen einer Heatmap\n",
    "sns.heatmap(heatmap_data, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "\n",
    "# Anpassen der Ausgabe\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style({'font.family': 'serif', 'fontcolor': 'black'})\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spalten mit hoher Korrelation löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df_dropped.drop('id', axis=1)\n",
    "df_dropped = df_dropped.drop('country_id', axis=1)\n",
    "df_dropped = df_dropped.drop('league_id', axis=1)\n",
    "df_dropped = df_dropped.drop('season', axis=1)\n",
    "df_dropped = df_dropped.drop('home_team_goal', axis=1)\n",
    "#df_dropped = df_dropped.drop('away_team_goal', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weitere Berechnungen und Beziehungen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ist eine Auswirkung von Heimspiel oder Auswärtsspiel zu erkennen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zähle die Anzahl der Vorkommnisse von -1, 0 und 1 in der Spalte 'label_outcome'\n",
    "count = df_dropped['label_outcome'].value_counts()\n",
    "\n",
    "# Berechne den Prozentsatz, den jeder Wert auf das gesamte Dataframe bezieht\n",
    "percent = df_dropped['label_outcome'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Gib die Ergebnisse aus\n",
    "print(count)\n",
    "print(percent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie wirkt sich die Anzahl der Rechtsfüßler in einem Team auf den Ausgang des Spiels aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen eines Streudiagramms mit der Anzahl der rechtsfüßigen Spieler und dem Ausgang des Spiels\n",
    "plt.scatter(df_dropped['right_foot_percentage_hometeam'], df_dropped['label_outcome'])\n",
    "plt.xlabel('Anzahl der rechtsfüßigen Spieler')\n",
    "plt.ylabel('Ausgang des Spiels')\n",
    "\n",
    "# Hinzufügen der Linie\n",
    "x = df_dropped['right_foot_percentage_hometeam']\n",
    "y = df_dropped['label_outcome']\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "plt.plot(x, slope*x + intercept, color='red')\n",
    "\n",
    "# Ausgabe des Diagramms\n",
    "plt.show()\n",
    "\n",
    "# Erstelle ein Heatmap-Diagramm mit der Anzahl der rechtsfüßigen Spieler und dem Ausgang des Spiels\n",
    "sns.heatmap(pd.crosstab(df_dropped['right_foot_percentage_hometeam'], df['label_outcome'], normalize='index'), cmap='coolwarm')\n",
    "plt.xlabel('Ausgang des Spiels')\n",
    "plt.ylabel('Anzahl der rechtsfüßigen Spieler')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie wirkt sich das Rating des Heimteams auf die Anzahl der Tore der Auswärtsmannschaft aus? #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswirkung von home_team_rating auf away_team_goal\n",
    "x = df_dropped['average_rating_hometeam']\n",
    "y = df_dropped['away_team_goal']\n",
    "\n",
    "df_dropped = df_dropped.drop('away_team_goal', axis=1)\n",
    "\n",
    "plt.scatter(x, y)  \n",
    "plt.plot(np.unique(x),np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = 'green')  \n",
    "print(\"Auswirkungen des average_rating_hometeam auf die Anzahl an Gegentoren:\")\n",
    "plt.xlabel(\"Rating des Heimteams\")\n",
    "plt.ylabel(\"Anzahl an Gegentoren des Auswärtsteams\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie wirkt sich das Rating des Heimteams auf den Spielausgang aus? #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswirkung von home_team_rating auf label_outcome\n",
    "x = df_dropped['average_rating_hometeam']\n",
    "y = df_dropped['label_outcome']\n",
    "\n",
    "plt.scatter(x, y)  \n",
    "plt.plot(np.unique(x),np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = 'green')  \n",
    "print(\"Auswirkungen des average_rating_hometeam auf den Spielausgang (Aus Sicht des Heimteams):\")\n",
    "plt.xlabel(\"Rating des Heimteams\")\n",
    "plt.ylabel(\"Spielausgang\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie wirkt sich das Rating des Auswärtsteams auf den Spielausgang aus? #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswirkung von away_team_rating auf label_outcome\n",
    "x = df_dropped['average_rating_awayteam']\n",
    "y = df_dropped['label_outcome']\n",
    "\n",
    "plt.scatter(x, y)  \n",
    "plt.plot(np.unique(x),np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = 'green')  \n",
    "print(\"Auswirkungen des average_rating_awayteam auf den Spielausgang (Aus Sicht des Heimteams):\")\n",
    "plt.xlabel(\"Rating des Auswärtsteams\")\n",
    "plt.ylabel(\"Spielausgang\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Trennung von Features und Zielvariablen\n",
    "features = df_dropped.drop('label_outcome', axis=1)\n",
    "target = df_dropped['label_outcome']\n",
    "\n",
    "\n",
    "# Definition des Modells\n",
    "model = LinearRegression()\n",
    "\n",
    "# Erstellung des RFE-Objekts mit 6 gewünschten Features (Ab 5 Features bleiben alle Metriken gleich)\n",
    "rfe = RFE(model, n_features_to_select=6)\n",
    "\n",
    "# Anpassung des RFE-Objekts an die Daten\n",
    "rfe.fit(features, target)\n",
    "\n",
    "# Ausgabe der ausgewählten Features\n",
    "selected_features = features.columns[rfe.support_]\n",
    "print(selected_features)\n",
    "\n",
    "# Trennung von Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features[selected_features], target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training des Modells\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage der Testdaten\n",
    "y_pred = model.predict(features_test)\n",
    "\n",
    "# Berechnung des R^2-Wertes\n",
    "r2 = r2_score(target_test, y_pred)\n",
    "print(\"R-squared value: {:.2f}\".format(r2))\n",
    "\n",
    "# Berechnung des Mean Squared Error\n",
    "mse = mean_squared_error(target_test, y_pred)\n",
    "print('MSE: {:.2f}'.format(mse))\n",
    "\n",
    "# Berechnung des Mean Absolute Error\n",
    "mae = mean_absolute_error(target_test, y_pred)\n",
    "print('MAE: {:.2f}'.format(mae))\n",
    "\n",
    "# Berechnung der Residuen\n",
    "residuals = target_test - y_pred\n",
    "\n",
    "# Erstellung des Residuenplots\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show() # Daten sollte zufällig um Null herum sein\n",
    "\n",
    "# Erstellung des Verteilungsplots\n",
    "sns.histplot(target_test, kde=True, color='b', label='Actual Values')\n",
    "sns.histplot(y_pred, kde=True, color='r', label='Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Erstellung des Scatterplots\n",
    "plt.scatter(target_test, y_pred)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "result = permutation_importance(model, features_test, target_test, n_repeats=10, random_state=42)\n",
    "importance = result.importances_mean\n",
    "plt.barh(selected_features, importance)\n",
    "plt.subplots_adjust(left=.3)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "coefs = model.coef_\n",
    "plt.barh(selected_features, coefs)\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.subplots_adjust(left=.3)\n",
    "plt.title(\"Feature Coefficients\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenführen der ausgewählten Features und des Zielvariablenvektors in ein Pandas DataFrame\n",
    "data = pd.concat([features[selected_features], target], axis=1)\n",
    "\n",
    "# Erstellung eines Paarplots, um die Beziehungen zwischen den Variablen zu visualisieren\n",
    "# x_vars: Ausgewählte Features, y_vars: Zielvariable\n",
    "sns.pairplot(data, x_vars=selected_features, y_vars='label_outcome', height=5, aspect=1, kind='reg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell trainieren\n",
    "model.fit(features[selected_features], target)\n",
    "\n",
    "# Vorhersagen treffen\n",
    "y_pred = model.predict(features[selected_features])\n",
    "\n",
    "# Regressionsplot erstellen\n",
    "sns.regplot(x=target, y=y_pred, ci=None)\n",
    "\n",
    "# Achsenbeschriftungen und Titel setzen\n",
    "plt.xlabel('Actual Outcome')\n",
    "plt.ylabel('Predicted Outcome')\n",
    "plt.title('Linear Regression Model')\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "# Entfernen von Zeilen, die NaN-Werte in der Zielvariablen enthalten\n",
    "df_dropped = df.dropna(subset=['label_outcome'])\n",
    "\n",
    "# Trennung von Features und Zielvariablen, Aussortieren von Features\n",
    "features = df_dropped.drop(['match_api_id', 'date', 'season', 'id', 'country_id', 'league_id', 'home_team_api_id', 'away_team_api_id', 'home_player_1', 'home_player_2', 'home_player_3', 'home_player_4', 'home_player_5', 'home_player_6', 'home_player_7','home_player_8', 'home_player_9', 'home_player_10', 'home_player_11', 'away_player_1', 'away_player_2', 'away_player_3', 'away_player_4', 'away_player_5', 'away_player_6', 'away_player_7','away_player_8', 'away_player_9', 'away_player_10', 'away_player_11', 'label_outcome', 'home_team_goal', 'away_team_goal'], axis=1)\n",
    "target = df_dropped['label_outcome']\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Test-Size 0.5, Genauigkeit: {accuracy}\")\n",
    "\n",
    "estimator = rf.estimators_[0]\n",
    "\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'], shell=True)\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'tree.png')\n",
    "display(tree)\n",
    "\n",
    "#### Finde die besten Hyperparameter\n",
    "\n",
    "# Definition der Hyperparameter und ihrer möglichen Werte\n",
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20),\n",
    "              'min_samples_split': randint(2,10),\n",
    "              'min_samples_leaf': randint(1,10)}\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialisierung des Randomized Search CV Objekts\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions=param_dist,\n",
    "                                 n_iter=10,\n",
    "                                 cv=5,\n",
    "                                 random_state=42)\n",
    "\n",
    "# Suche nach den besten Hyperparametern auf den Trainingsdaten\n",
    "rand_search.fit(features_train, target_train)\n",
    "\n",
    "# Ausgabe der besten Hyperparameter und der Genauigkeit auf den Testdaten\n",
    "print(f\"Beste Hyperparameter: {rand_search.best_params_}\")\n",
    "print(f\"Genauigkeit auf Testdaten: {rand_search.score(features_test, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Test-Size 0.1, Genauigkeit: {accuracy}\")\n",
    "\n",
    "estimator = rf.estimators_[0]\n",
    "\n",
    "export_graphviz(estimator, out_file='tree01.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree01.dot', '-o', 'tree01.png', '-Gdpi=600'], shell=True)\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'tree01.png')\n",
    "display(tree)\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42 ,max_depth=5)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Test-Size 0.1, Genauigkeit: {accuracy}\")\n",
    "\n",
    "estimator = rf.estimators_[0]\n",
    "\n",
    "export_graphviz(estimator, out_file='tree02.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree02.dot', '-o', 'tree02.png', '-Gdpi=600'], shell=True)\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'tree02.png')\n",
    "display(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition der Hyperparameter und ihrer möglichen Werte\n",
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20),\n",
    "              'min_samples_split': randint(2,10),\n",
    "              'min_samples_leaf': randint(1,10)}\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialisierung des Randomized Search CV Objekts\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions=param_dist,\n",
    "                                 n_iter=10,\n",
    "                                 cv=5,\n",
    "                                 random_state=42)\n",
    "\n",
    "# Suche nach den besten Hyperparametern auf den Trainingsdaten\n",
    "rand_search.fit(features_train, target_train)\n",
    "\n",
    "# Ausgabe der besten Hyperparameter und der Genauigkeit auf den Testdaten\n",
    "print(f\"Beste Hyperparameter: {rand_search.best_params_}\")\n",
    "print(f\"Genauigkeit auf Testdaten: {rand_search.score(features_test, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best estimator and index\n",
    "best_rf = rand_search.best_estimator_\n",
    "best_index = rand_search.best_index_\n",
    "\n",
    "# Visualize the best tree\n",
    "estimator = best_rf.estimators_[best_index]\n",
    "\n",
    "export_graphviz(estimator, out_file='treebest.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'treebest.dot', '-o', 'treebest.png', '-Gdpi=600'], shell=True)\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'treebest.png')\n",
    "display(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage auf den Testdaten mit den besten Hyperparametern\n",
    "best_rf = rand_search.best_estimator_\n",
    "target_pred = best_rf.predict(features_test)\n",
    "\n",
    "# Berechnung des F1-Scores\n",
    "f1 = f1_score(target_test, target_pred, average='weighted')\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Berechnung der AUC\n",
    "target_proba = best_rf.predict_proba(features_test)\n",
    "auc_score = roc_auc_score(target_test, target_proba, multi_class='ovr')\n",
    "print(f\"AUC: {auc_score}\")\n",
    "\n",
    "# Berechnung der Precision\n",
    "precision = precision_score(target_test, target_pred, average='weighted', zero_division=1)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Berechnung des Recall\n",
    "recall = recall_score(target_test, target_pred, average='weighted', zero_division=1)\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit des Random Forest Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Berechnung der Feature Importance\n",
    "importance = best_rf.feature_importances_\n",
    "sorted_idx = importance.argsort()[::-1]\n",
    "print(\"Feature importance:\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{features_train.columns[i]}: {importance[i]}\")\n",
    "\n",
    "# Erstellung der Confusion Matrix\n",
    "target_pred = rf.predict(features_test)\n",
    "conf_mat = confusion_matrix(target_test, target_pred)\n",
    "\n",
    "# Plot der Confusion Matrix\n",
    "plt.figure(figsize= (7,7))\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='g', \n",
    "            xticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], yticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the target variable\n",
    "target_bin = label_binarize(target_test, classes=rand_search.classes_)\n",
    "n_classes = target_bin.shape[1]\n",
    "\n",
    "# Compute the probabilities for each class\n",
    "target_proba = best_rf.predict_proba(features_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(target_bin[:, i], target_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(target_bin.ravel(), target_proba.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot the ROC curves for all classes and micro-average\n",
    "plt.figure()\n",
    "lw = 2\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve (area = %0.2f) for class %s' % (roc_auc[i], ['Win', 'Draw', 'Lose'][i]))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "# Add some visual enhancements\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trennung in ein Dataframe mit den Features und eines für die Zielvariable\n",
    "features_all = df_dropped.drop('label_outcome', axis=1)\n",
    "target_all = df_dropped['label_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herausnehmen der nicht sinnvollen Werte\n",
    "features_all = features_all.drop(['stage', 'match_api_id', 'date', 'home_team_api_id', 'away_team_api_id', 'home_player_1', 'home_player_2', 'home_player_3', 'home_player_4', 'home_player_5', 'home_player_6', 'home_player_7','home_player_8', 'home_player_9', 'home_player_10', 'home_player_11', 'away_player_1', 'away_player_2', 'away_player_3', 'away_player_4', 'away_player_5', 'away_player_6', 'away_player_7','away_player_8', 'away_player_9', 'away_player_10', 'away_player_11'], axis=1)\n",
    "\n",
    "# Errechnen des VIF für jedes Feature (Testen auf Multikollinarität -> liegt vor wenn VIF > 10)\n",
    "vif_scores = pd.DataFrame() \n",
    "vif_scores['Attribute'] = features_all.columns \n",
    "\n",
    "vif_scores['VIF Scores'] = [variance_inflation_factor(features_all.values, i) for i in range(len(features_all.columns))] \n",
    "display(vif_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herausnehmen der Größe, da der hohe VIF-Wert eine Abhängigkeit beschreibt -> Gewicht und Größe sind bei Sportlern meist voneinander abhängig\n",
    "features_all = features_all.drop([\"average_height_hometeam\", \"average_height_awayteam\"], axis=1)\n",
    "\n",
    "vif_scores = pd.DataFrame() \n",
    "vif_scores[\"Attribute\"] = features_all.columns \n",
    "vif_scores[\"VIF Scores\"] = [variance_inflation_factor(features_all.values, i) for i in range(len(features_all.columns))] \n",
    "display(vif_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bestimmen der Genauigkeit der Vorhersagen bei 2-10 Folds mithilfe des RepeatedKFolds # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluieren des Modells mit einer bestimmten Anzahl an Wiederholungen\n",
    "def evaluate_model(X, y, wiederholungen, s):\n",
    " # Vorbereiten der cross-validation-Prozedur\n",
    " crossvalidation = RepeatedKFold(n_splits=s, n_repeats=wiederholungen, random_state=1)\n",
    " # Modell erstellen\n",
    " modell = LogisticRegression()\n",
    " # Modell evaluieren\n",
    " ergebnis = cross_val_score(modell, X, y, scoring='accuracy', cv=crossvalidation, n_jobs=-1)\n",
    " return ergebnis\n",
    "\n",
    "wiederholungen = range(1,6)\n",
    "\n",
    "splits = range(2,11)\n",
    "for s in splits:\n",
    "    for w in wiederholungen:\n",
    "        scores = evaluate_model(features_all, target_all, w, s)\n",
    "        print(f\"Genauigkeit bei {s} Splits: {mean(scores)}\")\n",
    "    print(\"---------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bestimmen der Genauigkeit, Confusions-Matrix, R2-Score und Mean Squared Error (Train-Test-Split-Aufteilung von 10 bis 90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = range(1,10)\n",
    "for t in testSize:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_all, target_all, test_size=(t/10), random_state=42)\n",
    "    mymodel = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", penalty='l2', max_iter=5000)\n",
    "    mymodel.fit(X_train, y_train)\n",
    "\n",
    "    predicted_output = mymodel.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, predicted_output)\n",
    "    mse = mean_squared_error(y_test, predicted_output)\n",
    "    r2 = r2_score(y_test, predicted_output)\n",
    "    print(f\"Genauigkeit [bei einer Testgröße von {t*10}%]: {mymodel.score(X_test, y_test)}\")\n",
    "    print(f\"mean squared error: {mse}\")\n",
    "    print(f\"r2 score: {r2}\")\n",
    " \n",
    "    plt.figure(figsize= (7,7))\n",
    "    sns.heatmap(cm, yticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], xticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], annot=True, fmt='g')\n",
    "    plt.xlabel('Vorhergesagter Wert')\n",
    "    plt.ylabel('tatsächlicher Wert')\n",
    "    plt.show()\n",
    "    print(\"-------------------------------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genauere Betrachtung der logistischen Regression mit 10% Trainingsgröße und 90% Testgröße"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Klassen-Verteilung der Trainingsdaten: \")\n",
    "sns.countplot(x = y_train, data = features_all)\n",
    "plt.show()\n",
    "print(\"Klassen-Verteilung der Testdaten: \")\n",
    "sns.countplot(x = y_test, data = features_all)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_all, target_all, test_size=0.90, random_state=42)\n",
    "mymodel = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", penalty='l2', max_iter=5000)\n",
    "mymodel.fit(X_train, y_train)\n",
    "predicted_output = mymodel.predict(X_test)\n",
    "print(f\"Genauigkeit des Modells: {mymodel.score(X_test, y_test)}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, predicted_output)\n",
    "plt.figure(figsize= (7,7))\n",
    "sns.heatmap(cm, yticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], xticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], annot=True, fmt='g')\n",
    "plt.xlabel('Vorhergesagter Wert')\n",
    "plt.ylabel('tatsächlicher Wert')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predicted_output)\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logarithmische Koeffizienten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spalten = X_train.columns\n",
    "koeffizientenFürNiederlage = pd.Series(mymodel.coef_[0], spalten)\n",
    "koeffizientenFürUnentschieden = pd.Series(mymodel.coef_[1], spalten)\n",
    "koeffizientenFürSieg = pd.Series(mymodel.coef_[2], spalten)\n",
    "\n",
    "print(f\"Klasse: {mymodel.classes_}\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"logarithmische Koeffizienten:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse -1 (Niederlage):\")\n",
    "print(koeffizientenFürNiederlage)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 0 (Unentschieden):\")\n",
    "print(koeffizientenFürUnentschieden)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 1 (Sieg):\")\n",
    "print(koeffizientenFürSieg)\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zugehörige reguläre Koeffizienten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logarithmische zu regulären Werten umrechnen\n",
    "koeffizientenFürNiederlageRegulaer = pd.Series(np.exp(mymodel.coef_[0]), spalten)\n",
    "koeffizientenFürUnentschiedenRegulaer = pd.Series(np.exp(mymodel.coef_[1]), spalten)\n",
    "koeffizientenFürSiegRegulaer = pd.Series(np.exp(mymodel.coef_[2]), spalten)\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"reguläre Koeffizienten:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse -1 (Niederlage):\")\n",
    "print(koeffizientenFürNiederlageRegulaer)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 0 (Unentschieden):\")\n",
    "print(koeffizientenFürUnentschiedenRegulaer)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 1 (Sieg):\")\n",
    "print(koeffizientenFürSiegRegulaer)\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logarithmische Wahrscheinlichkeit, dass mithilfe dieses Features das Spielergebnis vorhergesagt werden kann\n",
    "print((\"logarithmische Wahrscheinlichkeit, dass ein Feature eine Niederlage vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürNiederlage.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"logarithmische Wahrscheinlichkeit\")\n",
    "plt.show()\n",
    "\n",
    "print((\"logarithmische Wahrscheinlichkeit, dass ein Feature ein Unentschieden vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürUnentschieden.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"logarithmische Wahrscheinlichkeit, dass ein Feature das Spielergebnis vorhersagen kann\")\n",
    "plt.show()\n",
    "\n",
    "print((\"logarithmische Wahrscheinlichkeit, dass ein Feature einen Sieg vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürSieg.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"logarithmische Wahrscheinlichkeit, dass ein Feature das Spielergebnis vorhersagen kann\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reguläre Wahrscheinlichkeit, dass mithilfe dieses Features das Spielergebnis vorhergesagt werden kann\n",
    "print((\"reguläre Wahrscheinlichkeit, dass ein Feature eine Niederlage vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürNiederlageRegulaer.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"reguläre Wahrscheinlichkeit\")\n",
    "plt.show()\n",
    "\n",
    "print((\"reguläre Wahrscheinlichkeit, dass ein Feature ein Unentschieden vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürUnentschiedenRegulaer.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"reguläre Wahrscheinlichkeit\")\n",
    "plt.show()\n",
    "\n",
    "print((\"reguläre Wahrscheinlichkeit, dass ein Feature einen Sieg vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürSiegRegulaer.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"reguläre Wahrscheinlichkeit\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betrachtung des Ergebnisses bei einem Testsplit von 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versuch, ob bei weniger Trainingsdaten auch Unentschieden besser vorhergesagt werden können\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_all, target_all, test_size=0.99, random_state=42)\n",
    "mymodel = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", penalty='l2', max_iter=5000)\n",
    "mymodel.fit(X_train, y_train)\n",
    "predicted_output = mymodel.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, predicted_output)\n",
    "mse = mean_squared_error(y_test, predicted_output)\n",
    "r2 = r2_score(y_test, predicted_output)\n",
    "print(f\"Genauigkeit [bei einer Testgröße von 99%]: {mymodel.score(X_test, y_test)}\")\n",
    "print(f\"mean squared error: {mse}\")\n",
    "print(f\"r2 score: {r2}\")\n",
    "\n",
    "plt.figure(figsize= (7,7))\n",
    "sns.heatmap(cm, yticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], xticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], annot=True, fmt='g')\n",
    "plt.xlabel('Vorhergesagter Wert')\n",
    "plt.ylabel('tatsächlicher Wert')\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(y_test, predicted_output)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
