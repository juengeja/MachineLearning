{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from numpy import mean, std\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import export_graphviz\n",
    "from scipy.stats import chi2_contingency, sem\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, RepeatedStratifiedKFold, StratifiedKFold,cross_val_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, precision_score, recall_score, confusion_matrix, auc, mean_squared_error, r2_score, classification_report\n",
    "from sklearn.preprocessing import label_binarize, scale\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = sqlite3.connect('database.sqlite')\n",
    "\n",
    "player_data = pd.read_sql(\"SELECT id, player_api_id, player_name, birthday, height, weight FROM Player\", cnx)\n",
    "player_stats_data = pd.read_sql(\"SELECT id, player_api_id, date, overall_rating, potential, preferred_foot, attacking_work_rate, defensive_work_rate, crossing, finishing, heading_accuracy, short_passing, volleys, dribbling, curve, free_kick_accuracy, long_passing, ball_control, acceleration, sprint_speed, agility, reactions, shot_power, jumping, stamina, strength, long_shots, aggression, interceptions, positioning, vision, penalties, marking, standing_tackle, sliding_tackle, gk_diving, gk_handling, gk_kicking, gk_positioning, gk_reflexes FROM Player_Attributes\", cnx)\n",
    "match_data = pd.read_sql(\"SELECT id, country_id, league_id, season, stage, date, match_api_id, home_team_api_id, away_team_api_id, home_team_goal, away_team_goal, home_player_1, home_player_2, home_player_3, home_player_4, home_player_5, home_player_6, home_player_7, home_player_8, home_player_9, home_player_10, home_player_11, away_player_1, away_player_2, away_player_3, away_player_4, away_player_5, away_player_6, away_player_7, away_player_8, away_player_9, away_player_10, away_player_11, goal, shoton, shotoff, foulcommit, card, cross, corner, possession, B365H, B365D, B365A FROM Match\", cnx)\n",
    "league_data = pd.read_sql(\"SELECT id, country_id, name FROM League\", cnx)\n",
    "country_data = pd.read_sql(\"SELECT id, name FROM Country\", cnx)\n",
    "team_data = pd.read_sql(\"SELECT id, team_api_id, team_long_name, team_short_name FROM Team\", cnx)\n",
    "team_attributes_data = pd.read_sql(\"SELECT id, team_api_id, date, buildUpPlaySpeed, buildUpPlaySpeedClass, buildUpPlayDribbling, buildUpPlayDribblingClass, buildUpPlayPassing, buildUpPlayPassingClass, buildUpPlayPositioningClass, chanceCreationPassing, chanceCreationPassingClass, chanceCreationCrossing, chanceCreationCrossingClass, chanceCreationShooting, chanceCreationShooting, chanceCreationPositioningClass, defencePressure, defencePressureClass, defenceAggression, defenceAggressionClass, defenceTeamWidth, defenceTeamWidthClass, defenceDefenderLineClass FROM Team_Attributes\", cnx)\n",
    "\n",
    "\n",
    "def null_counts( dataframe ):\n",
    "    '''\n",
    "    Get percentage of empty values per column\n",
    "\n",
    "    Args:\n",
    "        dataframe: dataframe containing at least one column and value\n",
    "\n",
    "    Returns:\n",
    "        Returns nothing, prints percentages\n",
    "    '''\n",
    "    null_counts = dataframe.isnull().sum()\n",
    "    null_percents = null_counts / len(dataframe) * 100\n",
    "    print(null_percents)\n",
    "\n",
    "\n",
    "null_counts(player_data)\n",
    "null_counts(player_stats_data)\n",
    "null_counts(match_data)\n",
    "null_counts(league_data)\n",
    "null_counts(country_data)\n",
    "null_counts(team_data)\n",
    "null_counts(team_attributes_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenaufbereitung\n",
    "In diesem Code-Abschnitt werden die Daten bereinigt und für das maschinelle Lernen aufbereitet. Dazu werden die im vorherigen Abschnitt gesammelten Erkenntnisse zu den Anteilen von Leeren Werten je Spalte dazu genutzt, Spalten mit mangelnder Aussagekraft vollständig zu entfernen (`drop()`). Daraufhin wird sich außerdem der verbliebenen leeren Werte in allen Zeilen angenommen.\n",
    "\n",
    "## Spielerratings\n",
    "Die Tabelle Player_Attributes (Dtaframe `player_stats_data`) enthält Spiellerratings für alle Spieler zu verschiedenen Zeitpunkten. Dabei haben manche Spieler mehrere Ratings pro Jahr, andere nur ein Rating pro Jahr, wieder andere nur ein Rating in mehreren Jahren. Um diese unterschiedlichen Vorraussetzungen für alle Spieler auf ein Niveau zu bringen, werden mehrere unterjährige Ratings auf ein einzelnes gemittelt. Im folgenden wird dann für jeden Spieler das Rating aus dem benötigten Jahr verwendet. Gibt es kein Rating aus diesem Jahr, wird das naheliegenste Rating herangezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = match_data.drop(columns=[\"goal\", \"shoton\", \"shotoff\", \"foulcommit\", \"card\", \"cross\", \"corner\", \"possession\"], axis=1)\n",
    "team_attributes_data = team_attributes_data.drop(\"buildUpPlayDribbling\", axis=1)\n",
    "\n",
    "df_dropped = match_data.dropna()\n",
    "player_stats_data = player_stats_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_nearest_rating(date, player_api_id):\n",
    "    '''\n",
    "    Get player rating closest to the provided date\n",
    "\n",
    "    Args:\n",
    "        date: Date as int. (yyyymmdd)\n",
    "        player_api_id: player_api_id as int.\n",
    "\n",
    "    Returns:\n",
    "        Returns a new dataframe containing all player attributes for the nearest date.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: No data for provided player_api_id\n",
    "    '''\n",
    "    all_ratings_for_player: pd.DataFrame = player_stats_data.loc[player_stats_data[\"player_api_id\"] == player_api_id]\n",
    "    if (all_ratings_for_player.empty):\n",
    "        raise ValueError(f\"No data for provided player_api_id: {player_api_id}\")\n",
    "    if (len(all_ratings_for_player.index) == 1):\n",
    "        return all_ratings_for_player\n",
    "    intdate: pd.DataFrame = pd.DataFrame(columns=[\"date\"], dtype=np.int8)\n",
    "    for index, row in all_ratings_for_player.iterrows():\n",
    "        rowdate: str = row[\"date\"][:10]\n",
    "        rowdate = rowdate.replace('-', '')\n",
    "        intdate.loc[index] = int(rowdate)\n",
    "    intdate = intdate.set_index('date')\n",
    "    intdate.sort_index(inplace = True)\n",
    "    index = intdate.index.get_indexer([date], method=\"nearest\")\n",
    "    all_ratings_for_player.reset_index(inplace=True, drop=True)\n",
    "    return all_ratings_for_player.loc[index]\n",
    "\n",
    "def get_average_team_rating(dataframe, matchdate):\n",
    "    teamRating: int = 0\n",
    "    missingPlayers = 0\n",
    "    for name, series in dataframe.items():\n",
    "        try:\n",
    "            teamRating = teamRating + int(get_nearest_rating(date=matchdate, player_api_id=int(series.item()))[\"overall_rating\"])\n",
    "        except ValueError:\n",
    "            missingPlayers += 1  \n",
    "    return teamRating / (11 - missingPlayers)\n",
    "\n",
    "\n",
    "def get_player_height(player_api_id):\n",
    "    singleHeight = (player_data['height'].loc[player_data['player_api_id'] == player_api_id]).item()\n",
    "    if not singleHeight:\n",
    "        raise ValueError(f\"No height-value for provided player_api_id: {player_api_id}\")\n",
    "    else:\n",
    "        return singleHeight\n",
    "    \n",
    "\n",
    "def get_player_weight(player_api_id):\n",
    "    singleWeight = (player_data['weight'].loc[player_data['player_api_id'] == player_api_id]).item()\n",
    "    if not singleWeight:\n",
    "        raise ValueError(f\"No weight-value for provided player_api_id: {player_api_id}\")\n",
    "    else:\n",
    "        return singleWeight\n",
    "\n",
    "\n",
    "def get_player_age(player_api_id, date):\n",
    "    birthdate = (player_data['birthday'].loc[player_data['player_api_id'] == player_api_id]).item()\n",
    "    if not birthdate:\n",
    "        raise ValueError(f\"No age-value for provided player_api_id: {player_api_id}\")\n",
    "    else:\n",
    "        birthdate = birthdate[:10]\n",
    "        birthdate = birthdate.replace('-', '') \n",
    "\n",
    "        matchYear = str(date)[:4]\n",
    "        birthYear = str(birthdate)[:4]\n",
    "        matchMonth = str(date)[4:6]\n",
    "        birthMonth = str(birthdate)[4:6]\n",
    "\n",
    "        if int(matchMonth) < int(birthMonth):\n",
    "            return int(matchYear) - int(birthYear) - 1\n",
    "        elif int(matchMonth) == int(birthMonth):\n",
    "            matchDay = str(date)[6:8]\n",
    "            birthDay = str(birthdate)[6:8]\n",
    "            if(int(matchDay) < int(birthDay)):\n",
    "                return int(matchYear) - int(birthYear)\n",
    "            else:\n",
    "                return int(matchYear) - int(birthYear) \n",
    "        else:\n",
    "            return int(matchYear) - int(birthYear)\n",
    "\n",
    "\n",
    "def get_strong_foot(player_api_id):\n",
    "    \n",
    "    df_all_feet_player = player_stats_data['preferred_foot'].loc[player_stats_data['player_api_id'] == player_api_id]\n",
    "    df_all_feet_player.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    if df_all_feet_player.empty:\n",
    "        raise ValueError(f\"No preferred_foot-value for provided player_api_id: {player_api_id}\")\n",
    "    strongFoot = df_all_feet_player[0]\n",
    "    \n",
    "    if str(strongFoot) == 'right':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def set_label(dataframe):\n",
    "    homeGoals = dataframe['home_team_goal'].item()\n",
    "    awayGoals = dataframe['away_team_goal'].item()\n",
    "\n",
    "    if homeGoals > awayGoals:\n",
    "        return 'Win'\n",
    "    if homeGoals < awayGoals:\n",
    "        return 'Lose'\n",
    "    if homeGoals == awayGoals:\n",
    "        return 'Draw'\n",
    "\n",
    "\n",
    "def get_last_three_matches(team_api_id, date):\n",
    "    allHomeGamesOfTeam = match_data[['date', 'match_api_id', 'home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']].loc[match_data['home_team_api_id'] == team_api_id]\n",
    "    allAwayGamesOfTeam = match_data[['date', 'match_api_id', 'home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']].loc[match_data['away_team_api_id'] == team_api_id]\n",
    "    allGamesOfTeam = pd.concat([allHomeGamesOfTeam, allAwayGamesOfTeam],axis=0, join='inner')\n",
    "    allGamesOfTeam = allGamesOfTeam.sort_values(by=['date'])\n",
    "    for dateIndex, item in allGamesOfTeam['date'].iteritems():\n",
    "        itemdate: str = item[:10]\n",
    "        itemdate = itemdate.replace('-', '')\n",
    "        allGamesOfTeam.loc[dateIndex, 'date'] = int(itemdate)\n",
    "    allGamesOfTeam = allGamesOfTeam.reset_index()\n",
    "    indexOfMatch = allGamesOfTeam.loc[allGamesOfTeam['date'] == date].index\n",
    "    try:\n",
    "        lastMatch = allGamesOfTeam[['home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']].loc[(indexOfMatch - 1)]\n",
    "        lastMatchValue = get_match_value(lastMatch, team_api_id)\n",
    "    except:\n",
    "        lastMatchValue = 0\n",
    "    try:\n",
    "        secondLastMatch = allGamesOfTeam[['home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']].loc[(indexOfMatch - 2)]\n",
    "        secondLastMatchValue = get_match_value(secondLastMatch, team_api_id)\n",
    "    except:\n",
    "        secondLastMatchValue = 0\n",
    "    try:\n",
    "        thirdLastMatch = allGamesOfTeam[['home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']].loc[(indexOfMatch - 3)]\n",
    "        thirdLastMatchValue = get_match_value(thirdLastMatch, team_api_id)\n",
    "    except:\n",
    "        thirdLastMatchValue = 0\n",
    "    return (lastMatchValue + secondLastMatchValue + thirdLastMatchValue) \n",
    "\n",
    "\n",
    "\n",
    "def get_match_value(dataframe, team_api_id):\n",
    "    if (dataframe['home_team_api_id'].item() == team_api_id):\n",
    "        ownGoals = dataframe['home_team_goal'].item()\n",
    "        otherGoals = dataframe['away_team_goal'].item()\n",
    "    else:\n",
    "        ownGoals = dataframe['away_team_goal'].item()\n",
    "        otherGoals = dataframe['home_team_goal'].item()\n",
    "\n",
    "    if ownGoals > otherGoals:\n",
    "        return 3\n",
    "    if ownGoals < otherGoals:\n",
    "        return 0\n",
    "    if ownGoals == otherGoals:\n",
    "        return 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_dropped = df_dropped.assign(average_rating_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_rating_awayteam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_height_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_height_awayteam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_weight_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_weight_awayteam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_age_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_age_awayteam=np.NaN)\n",
    "df_dropped = df_dropped.assign(right_foot_percentage_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(right_foot_percentage_awayteam=np.NaN)\n",
    "df_dropped = df_dropped.assign(label_outcome=np.NaN)\n",
    "df_dropped = df_dropped.assign(last_three_matches_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(last_three_matches_awayteam=np.NaN)\n",
    "\n",
    "\n",
    "\n",
    "for index, match_api_id in df_dropped['match_api_id'].iteritems():\n",
    "    home_api_id = match_data['home_team_api_id'].loc[match_data['match_api_id'] == match_api_id].item()\n",
    "    away_api_id = match_data['away_team_api_id'].loc[match_data['match_api_id'] == match_api_id].item()\n",
    "\n",
    "\n",
    "    df_match = match_data.loc[match_data[\"match_api_id\"] == match_api_id]\n",
    "    df_match_home_player = df_match[[\"home_player_1\", \"home_player_2\", \"home_player_3\", \"home_player_4\", \"home_player_5\", \"home_player_6\", \"home_player_7\",\"home_player_8\", \"home_player_9\", \"home_player_10\", \"home_player_11\"]]\n",
    "    df_match_away_player = df_match[[\"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\", \"away_player_5\", \"away_player_6\", \"away_player_7\",\"away_player_8\", \"away_player_9\", \"away_player_10\", \"away_player_11\"]] \n",
    "\n",
    "    matchDate: str = df_match[\"date\"].item()\n",
    "    matchDate = matchDate[:10]\n",
    "    matchDate = matchDate.replace('-', '')\n",
    "    matchDateInt: np.int8 = int(matchDate)\n",
    "\n",
    "    average_team_rating_home = get_average_team_rating(dataframe=df_match_home_player, matchdate=matchDateInt)\n",
    "    average_team_rating_away = get_average_team_rating(dataframe=df_match_away_player, matchdate=matchDateInt)\n",
    "\n",
    "    lastThreeMatchesHome = get_last_three_matches(home_api_id, matchDateInt)\n",
    "    lastThreeMatchesAway = get_last_three_matches(away_api_id, matchDateInt)\n",
    "\n",
    "    teamHeightHome = 0\n",
    "    teamWeightHome = 0\n",
    "    teamAgeHome = 0\n",
    "    teamRightFootPercentageHome = 0\n",
    "    missingPlayerHeightHome = 0\n",
    "    missingPlayerWeightHome = 0\n",
    "    missingPlayerAgeHome = 0\n",
    "    missingPlayerStrongFootHome = 0\n",
    "\n",
    "    for name, series in df_match_home_player.items():\n",
    "        try:\n",
    "            teamHeightHome = teamHeightHome + int(get_player_height(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerHeightHome += 1  \n",
    "\n",
    "        try:\n",
    "            teamWeightHome = teamWeightHome + int(get_player_weight(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerWeightHome += 1  \n",
    "\n",
    "        try:\n",
    "            teamAgeHome = teamAgeHome + int(get_player_age(player_api_id=int(series.item()), date=matchDateInt))\n",
    "        except ValueError:\n",
    "            missingPlayerAgeHome += 1  \n",
    "\n",
    "        try:\n",
    "            teamRightFootPercentageHome = teamRightFootPercentageHome + int(get_strong_foot(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerStrongFootHome += 1  \n",
    "\n",
    "    teamHeightHome = teamHeightHome / (11 - missingPlayerHeightHome)\n",
    "    teamWeightHome = teamWeightHome / (11 - missingPlayerWeightHome)\n",
    "    teamAgeHome = teamAgeHome / (11 - missingPlayerWeightHome)\n",
    "    teamRightFootPercentageHome = teamRightFootPercentageHome / (11 - missingPlayerStrongFootHome)\n",
    "\n",
    "\n",
    "    teamHeightAway = 0\n",
    "    teamWeightAway = 0\n",
    "    teamAgeAway = 0\n",
    "    teamRightFootPercentageAway = 0\n",
    "    missingPlayerHeightAway = 0\n",
    "    missingPlayerWeightAway = 0\n",
    "    missingPlayerAgeAway = 0\n",
    "    missingPlayerStrongFootAway = 0\n",
    "\n",
    "    for name, series in df_match_away_player.items():\n",
    "        try:\n",
    "            teamHeightAway = teamHeightAway + int(get_player_height(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerHeightAway += 1  \n",
    "\n",
    "        try:\n",
    "            teamWeightAway = teamWeightAway + int(get_player_weight(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerWeightAway += 1  \n",
    "\n",
    "        try:\n",
    "            teamAgeAway = teamAgeAway + int(get_player_age(player_api_id=int(series.item()), date=matchDateInt))\n",
    "        except ValueError:\n",
    "            missingPlayerAgeAway += 1  \n",
    "\n",
    "        try:\n",
    "            teamRightFootPercentageAway = teamRightFootPercentageAway + int(get_strong_foot(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerStrongFootAway += 1  \n",
    "\n",
    "    teamHeightAway = teamHeightAway / (11 - missingPlayerHeightAway)\n",
    "    teamWeightAway = teamWeightAway / (11 - missingPlayerWeightAway)\n",
    "    teamAgeAway = teamAgeAway / (11 - missingPlayerWeightAway)\n",
    "    teamRightFootPercentageAway = teamRightFootPercentageAway / (11 - missingPlayerStrongFootAway)\n",
    "    label_outcome = set_label(df_match)\n",
    "\n",
    "    df_dropped.loc[index,'average_rating_hometeam'] = average_team_rating_home\n",
    "    df_dropped.loc[index,'average_rating_awayteam'] = average_team_rating_away\n",
    "    df_dropped.loc[index,'average_height_hometeam'] = teamHeightHome\n",
    "    df_dropped.loc[index,'average_height_awayteam'] = teamHeightAway\n",
    "    df_dropped.loc[index,'average_weight_hometeam'] = teamWeightHome\n",
    "    df_dropped.loc[index,'average_weight_awayteam'] = teamWeightAway\n",
    "    df_dropped.loc[index,'average_age_hometeam'] = teamAgeHome\n",
    "    df_dropped.loc[index,'average_age_awayteam'] = teamAgeAway\n",
    "    df_dropped.loc[index,'right_foot_percentage_hometeam'] = teamRightFootPercentageHome\n",
    "    df_dropped.loc[index,'right_foot_percentage_awayteam'] = teamRightFootPercentageAway\n",
    "    df_dropped.loc[index,'label_outcome'] = label_outcome\n",
    "    df_dropped.loc[index,'last_three_matches_hometeam'] = lastThreeMatchesHome\n",
    "    df_dropped.loc[index,'last_three_matches_awayteam'] = lastThreeMatchesAway\n",
    "\n",
    "    #print(df_dropped)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bereinigte Daten einholen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindung zur SQLite-Datenbank herstellen\n",
    "conn = sqlite3.connect('neue_datenbank_numeric.db')\n",
    "\n",
    "# SQL-Abfrage ausführen und Ergebnis in ein Pandas-Dataframe laden\n",
    "df = pd.read_sql(\"SELECT * FROM neue_tabelle_mit_allen_numerischen_Daten\", conn)\n",
    "\n",
    "# Verbindung schließen\n",
    "conn.close()\n",
    "\n",
    "df_dropped = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korrelation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrelaitonsmatrix erstellt und in corr_matrix gespeichert => enthält Korrleationskoeffizienten zwischen allen möglichen Paaren\n",
    "corr_matrix = df_dropped.corr()\n",
    "\n",
    "# stack() wandelt Matrix in Series um, bei der jedes Element ein Paar von Spaltennamen und der Korrelationskoeffizient zwischen diesen Spalten ist\n",
    "# [abs(corr_matrix) > 0.9] reduziert die Werte auf nur Werte mit einem Wert über 0.9\n",
    "high_corr_pairs = corr_matrix.stack()[abs(corr_matrix.stack()) > 0.9]\n",
    "\n",
    "# Indizes der Serie werden zu Spaltennamen des Dataframe \n",
    "high_corr_pairs = high_corr_pairs.reset_index()\n",
    "\n",
    "# Spaltennamen des DataFrames umbenannt für bessere Lesbarkeit\n",
    "high_corr_pairs.columns = ['Column 1', 'Column 2', 'Correlation']\n",
    "\n",
    "print(high_corr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask for upper triangle\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Create heatmap with custom threshold\n",
    "plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(corr_matrix[(corr_matrix >= 0.3) | (corr_matrix <= -0.3)],\n",
    "            cmap='coolwarm', annot=True, fmt='.2f', mask=mask)\n",
    "\n",
    "# set the font color to black\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style({'font.family': 'serif', 'fontcolor': 'black'})\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # erstelle ein Dataframe für die Ergebnis von Chi2\n",
    "chi2_results_df = pd.DataFrame(columns=['Column 1', 'Column 2', 'Chi-Squared', 'P-Value'])\n",
    "\n",
    "# iteriert über jede Spalte des Dataframes\n",
    "for col in df_dropped.columns:\n",
    "    comparison_col = col\n",
    "\n",
    "    # iteriert über jede Spalte des Dataframes\n",
    "    for col in df_dropped.columns:\n",
    "\n",
    "        # überspringt den Schritt, wenn die Spalten die gleichen sind\n",
    "        if col == comparison_col:\n",
    "            continue\n",
    "\n",
    "        # erstellt eine Kontingenztabelle\n",
    "        contingency_table = pd.crosstab(df_dropped[comparison_col], df_dropped[col])\n",
    "\n",
    "        # führt chi2 aus und printed das Ergebnis\n",
    "        chi2, pval, dof, expected = chi2_contingency(contingency_table)\n",
    "                    #print(f\\Chi-squared test for columns '{comparison_col}' and '{col}': chi2={chi2}, pval={pval}\\)\n",
    "        chi2_results_df = chi2_results_df.append({'Column 1': comparison_col, 'Column 2': col, 'Chi-Squared': chi2, 'P-Value': pval}, ignore_index=True)\n",
    "\n",
    "    print(chi2_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# pivot the chi2_results_df to make a matrix\n",
    "heatmap_data = chi2_results_df.pivot(index='Column 1', columns='Column 2', values='P-Value')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "# create a heatmap\n",
    "sns.heatmap(heatmap_data, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "\n",
    "# set the font color to black\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style({'font.family': 'serif', 'fontcolor': 'black'})\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spalten mit hoher Korrelation löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df_dropped.drop('id', axis=1)\n",
    "df_dropped = df_dropped.drop('country_id', axis=1)\n",
    "df_dropped = df_dropped.drop('league_id', axis=1)\n",
    "df_dropped = df_dropped.drop('season', axis=1)\n",
    "df_dropped = df_dropped.drop('home_team_goal', axis=1)\n",
    "#df_dropped = df_dropped.drop('away_team_goal', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weitere Berechnungen und Beziehungen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ist eine Auswirkung von Heimspiel oder Auswärtsspiel zu erkennen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zähle die Anzahl der Vorkommnisse von -1, 0 und 1 in der Spalte 'label_outcome'\n",
    "count = df_dropped['label_outcome'].value_counts()\n",
    "\n",
    "# Berechne den Prozentsatz, den jeder Wert auf das gesamte Dataframe bezieht\n",
    "percent = df_dropped['label_outcome'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Gib die Ergebnisse aus\n",
    "print(count)\n",
    "print(percent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie wirkt sich die Anzahl der Rechtsfüßler in einem Team auf den Ausgang des Spiels aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen eines Streudiagramms mit der Anzahl der rechtsfüßigen Spieler und dem Ausgang des Spiels\n",
    "plt.scatter(df_dropped['right_foot_percentage_hometeam'], df_dropped['label_outcome'])\n",
    "plt.xlabel('Anzahl der rechtsfüßigen Spieler')\n",
    "plt.ylabel('Ausgang des Spiels')\n",
    "\n",
    "# Hinzufügen der Linie\n",
    "x = df_dropped['right_foot_percentage_hometeam']\n",
    "y = df_dropped['label_outcome']\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "plt.plot(x, slope*x + intercept, color='red')\n",
    "\n",
    "# Ausgabe des Diagramms\n",
    "plt.show()\n",
    "\n",
    "# Erstelle ein Heatmap-Diagramm mit der Anzahl der rechtsfüßigen Spieler und dem Ausgang des Spiels\n",
    "sns.heatmap(pd.crosstab(df_dropped['right_foot_percentage_hometeam'], df['label_outcome'], normalize='index'), cmap='coolwarm')\n",
    "plt.xlabel('Ausgang des Spiels')\n",
    "plt.ylabel('Anzahl der rechtsfüßigen Spieler')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie wirkt sich das Rating des Heimteams auf die Anzahl der Tore der Auswärtsmannschaft aus? #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswirkung von home_team_rating auf away_team_goal\n",
    "x = df_dropped['average_rating_hometeam']\n",
    "y = df_dropped['away_team_goal']\n",
    "\n",
    "df_dropped = df_dropped.drop('away_team_goal', axis=1)\n",
    "\n",
    "plt.scatter(x, y)  \n",
    "plt.plot(np.unique(x),np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = 'green')  \n",
    "print(\"Auswirkungen des average_rating_hometeam auf die Anzahl an Gegentoren:\")\n",
    "plt.xlabel(\"Rating des Heimteams\")\n",
    "plt.ylabel(\"Anzahl an Gegentoren des Auswärtsteams\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie wirkt sich das Rating des Heimteams auf den Spielausgang aus? #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswirkung von home_team_rating auf label_outcome\n",
    "x = df_dropped['average_rating_hometeam']\n",
    "y = df_dropped['label_outcome']\n",
    "\n",
    "plt.scatter(x, y)  \n",
    "plt.plot(np.unique(x),np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = 'green')  \n",
    "print(\"Auswirkungen des average_rating_hometeam auf den Spielausgang (Aus Sicht des Heimteams):\")\n",
    "plt.xlabel(\"Rating des Heimteams\")\n",
    "plt.ylabel(\"Spielausgang\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie wirkt sich das Rating des Auswärtsteams auf den Spielausgang aus? #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswirkung von away_team_rating auf label_outcome\n",
    "x = df_dropped['average_rating_awayteam']\n",
    "y = df_dropped['label_outcome']\n",
    "\n",
    "plt.scatter(x, y)  \n",
    "plt.plot(np.unique(x),np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = 'green')  \n",
    "print(\"Auswirkungen des average_rating_awayteam auf den Spielausgang (Aus Sicht des Heimteams):\")\n",
    "plt.xlabel(\"Rating des Auswärtsteams\")\n",
    "plt.ylabel(\"Spielausgang\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Trennung von Features und Zielvariablen\n",
    "features = df_dropped.drop('label_outcome', axis=1)\n",
    "target = df_dropped['label_outcome']\n",
    "\n",
    "\n",
    "# Definition des Modells\n",
    "model = LinearRegression()\n",
    "\n",
    "# Erstellung des RFE-Objekts mit 6 gewünschten Features (Ab 5 Features bleiben alle Metriken gleich)\n",
    "rfe = RFE(model, n_features_to_select=6)\n",
    "\n",
    "# Anpassung des RFE-Objekts an die Daten\n",
    "rfe.fit(features, target)\n",
    "\n",
    "# Ausgabe der ausgewählten Features\n",
    "selected_features = features.columns[rfe.support_]\n",
    "print(selected_features)\n",
    "\n",
    "# Trennung von Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features[selected_features], target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training des Modells\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage der Testdaten\n",
    "y_pred = model.predict(features_test)\n",
    "\n",
    "# Berechnung des R^2-Wertes\n",
    "r2 = r2_score(target_test, y_pred)\n",
    "print(\"R-squared value: {:.2f}\".format(r2))\n",
    "\n",
    "# Berechnung des Mean Squared Error\n",
    "mse = mean_squared_error(target_test, y_pred)\n",
    "print('MSE: {:.2f}'.format(mse))\n",
    "\n",
    "# Berechnung des Mean Absolute Error\n",
    "mae = mean_absolute_error(target_test, y_pred)\n",
    "print('MAE: {:.2f}'.format(mae))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Berechnung der Residuen\n",
    "residuals = target_test - y_pred\n",
    "\n",
    "# Erstellung des Residuenplots\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show() # Daten sollte zufällig um Null herum sein\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Erstellung des Verteilungsplots\n",
    "sns.histplot(target_test, kde=True, color='b', label='Actual Values')\n",
    "sns.histplot(y_pred, kde=True, color='r', label='Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Erstellung des Scatterplots\n",
    "plt.scatter(target_test, y_pred)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(model, features_test, target_test, n_repeats=10, random_state=42)\n",
    "importance = result.importances_mean\n",
    "plt.barh(selected_features, importance)\n",
    "plt.subplots_adjust(left=.3)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "coefs = model.coef_\n",
    "plt.barh(selected_features, coefs)\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.subplots_adjust(left=.3)\n",
    "plt.title(\"Feature Coefficients\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming you have split your data into features and target\n",
    "# and have selected the desired features for the model\n",
    "# you can create a dataframe with the selected features and the target variable\n",
    "data = pd.concat([features[selected_features], target], axis=1)\n",
    "\n",
    "# create a pairplot to visualize the relationships between the variables\n",
    "sns.pairplot(data, x_vars=selected_features, y_vars='label_outcome', height=5, aspect=1, kind='reg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model\n",
    "model.fit(features[selected_features], target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features[selected_features])\n",
    "\n",
    "# Create a regression plot\n",
    "sns.regplot(x=target, y=y_pred, ci=None)\n",
    "\n",
    "# Set the axis labels and title\n",
    "plt.xlabel('Actual Outcome')\n",
    "plt.ylabel('Predicted Outcome')\n",
    "plt.title('Linear Regression Model')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from random import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "# Entfernen von Zeilen, die NaN-Werte in der Zielvariablen enthalten\n",
    "df_dropped = df.dropna(subset=['label_outcome'])\n",
    "\n",
    "# Trennung von Features und Zielvariablen, Aussortieren von Features\n",
    "features = df_dropped.drop(['match_api_id', 'date', 'season', 'id', 'country_id', 'league_id', 'home_team_api_id', 'away_team_api_id', 'home_player_1', 'home_player_2', 'home_player_3', 'home_player_4', 'home_player_5', 'home_player_6', 'home_player_7','home_player_8', 'home_player_9', 'home_player_10', 'home_player_11', 'away_player_1', 'away_player_2', 'away_player_3', 'away_player_4', 'away_player_5', 'away_player_6', 'away_player_7','away_player_8', 'away_player_9', 'away_player_10', 'away_player_11', 'label_outcome', 'home_team_goal', 'away_team_goal'], axis=1)\n",
    "target = df_dropped['label_outcome']\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Test-Size 0.5, Genauigkeit: {accuracy}\")\n",
    "\n",
    "estimator = rf.estimators_[0]\n",
    "\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'tree.png')\n",
    "display(tree)\n",
    "\n",
    "#### Finde die besten Hyperparameter\n",
    "\n",
    "# Definition der Hyperparameter und ihrer möglichen Werte\n",
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20),\n",
    "              'min_samples_split': randint(2,10),\n",
    "              'min_samples_leaf': randint(1,10)}\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialisierung des Randomized Search CV Objekts\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions=param_dist,\n",
    "                                 n_iter=10,\n",
    "                                 cv=5,\n",
    "                                 random_state=42)\n",
    "\n",
    "# Suche nach den besten Hyperparametern auf den Trainingsdaten\n",
    "rand_search.fit(features_train, target_train)\n",
    "\n",
    "# Ausgabe der besten Hyperparameter und der Genauigkeit auf den Testdaten\n",
    "print(f\"Beste Hyperparameter: {rand_search.best_params_}\")\n",
    "print(f\"Genauigkeit auf Testdaten: {rand_search.score(features_test, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Test-Size 0.1, Genauigkeit: {accuracy}\")\n",
    "\n",
    "estimator = rf.estimators_[0]\n",
    "\n",
    "export_graphviz(estimator, out_file='tree01.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree01.dot', '-o', 'tree01.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'tree01.png')\n",
    "display(tree)\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42 ,max_depth=5)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Test-Size 0.1, Genauigkeit: {accuracy}\")\n",
    "\n",
    "estimator = rf.estimators_[0]\n",
    "\n",
    "export_graphviz(estimator, out_file='tree02.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree02.dot', '-o', 'tree02.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'tree02.png')\n",
    "display(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition der Hyperparameter und ihrer möglichen Werte\n",
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20),\n",
    "              'min_samples_split': randint(2,10),\n",
    "              'min_samples_leaf': randint(1,10)}\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialisierung des Randomized Search CV Objekts\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions=param_dist,\n",
    "                                 n_iter=10,\n",
    "                                 cv=5,\n",
    "                                 random_state=42)\n",
    "\n",
    "# Suche nach den besten Hyperparametern auf den Trainingsdaten\n",
    "rand_search.fit(features_train, target_train)\n",
    "\n",
    "# Ausgabe der besten Hyperparameter und der Genauigkeit auf den Testdaten\n",
    "print(f\"Beste Hyperparameter: {rand_search.best_params_}\")\n",
    "print(f\"Genauigkeit auf Testdaten: {rand_search.score(features_test, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best estimator and index\n",
    "best_rf = rand_search.best_estimator_\n",
    "best_index = rand_search.best_index_\n",
    "\n",
    "# Visualize the best tree\n",
    "estimator = best_rf.estimators_[best_index]\n",
    "\n",
    "export_graphviz(estimator, out_file='treebest.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'treebest.dot', '-o', 'treebest.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'treebest.png')\n",
    "display(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage auf den Testdaten mit den besten Hyperparametern\n",
    "best_rf = rand_search.best_estimator_\n",
    "target_pred = best_rf.predict(features_test)\n",
    "\n",
    "# Berechnung des F1-Scores\n",
    "f1 = f1_score(target_test, target_pred, average='weighted')\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Berechnung der AUC\n",
    "target_proba = best_rf.predict_proba(features_test)\n",
    "auc = roc_auc_score(target_test, target_proba, multi_class='ovr')\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "# Berechnung der Precision\n",
    "precision = precision_score(target_test, target_pred, average='weighted', zero_division=1)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Berechnung des Recall\n",
    "recall = recall_score(target_test, target_pred, average='weighted', zero_division=1)\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit des Random Forest Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Berechnung der Feature Importance\n",
    "importance = best_rf.feature_importances_\n",
    "sorted_idx = importance.argsort()[::-1]\n",
    "print(\"Feature importance:\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{features_train.columns[i]}: {importance[i]}\")\n",
    "\n",
    "# Erstellung der Confusion Matrix\n",
    "target_pred = rf.predict(features_test)\n",
    "conf_mat = confusion_matrix(target_test, target_pred)\n",
    "\n",
    "# Plot der Confusion Matrix\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='g', \n",
    "            xticklabels=rf.classes_, yticklabels=rf.classes_)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the target variable\n",
    "target_bin = label_binarize(target_test, classes=['Win', 'Draw', 'Lose'])\n",
    "n_classes = target_bin.shape[1]\n",
    "\n",
    "# Compute the probabilities for each class\n",
    "target_proba = best_rf.predict_proba(features_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(target_bin[:, i], target_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(target_bin.ravel(), target_proba.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot the ROC curves for all classes and micro-average\n",
    "plt.figure()\n",
    "lw = 2\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve (area = %0.2f) for class %s' % (roc_auc[i], ['Win', 'Draw', 'Lose'][i]))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "# Add some visual enhancements\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trennung in ein Dataframe mit den Features und eines für die Zielvariable\n",
    "features_all = df_dropped.drop('label_outcome', axis=1)\n",
    "target_all = df_dropped['label_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herausnehmen der nicht sinnvollen Werte\n",
    "features_all = features_all.drop([\"stage\", \"match_api_id\", \"date\", \"home_team_api_id\", \"away_team_api_id\", \"home_player_1\", \"home_player_2\", \"home_player_3\", \"home_player_4\", \"home_player_5\", \"home_player_6\", \"home_player_7\",\"home_player_8\", \"home_player_9\", \"home_player_10\", \"home_player_11\", \"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\", \"away_player_5\", \"away_player_6\", \"away_player_7\",\"away_player_8\", \"away_player_9\", \"away_player_10\", \"away_player_11\"], axis=1)\n",
    "\n",
    "# Errechnen des VIF für jedes Feature (Testen auf Multikollinarität -> liegt vor wenn VIF > 10)\n",
    "vif_scores = pd.DataFrame() \n",
    "vif_scores[\"Attribute\"] = features_all.columns \n",
    "\n",
    "vif_scores[\"VIF Scores\"] = [variance_inflation_factor(features_all.values, i) for i in range(len(features_all.columns))] \n",
    "display(vif_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herausnehmen der Größe, da der hohe VIF-Wert eine Abhängigkeit beschreibt -> Gewicht und Größe sind bei Sportlern meist voneinander abhängig\n",
    "features_all = features_all.drop([\"average_height_hometeam\", \"average_height_awayteam\"], axis=1)\n",
    "\n",
    "vif_scores = pd.DataFrame() \n",
    "vif_scores[\"Attribute\"] = features_all.columns \n",
    "vif_scores[\"VIF Scores\"] = [variance_inflation_factor(features_all.values, i) for i in range(len(features_all.columns))] \n",
    "display(vif_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bestimmen der Genauigkeit der Vorhersagen bei 2-10 Folds mithilfe des RepeatedKFolds # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluieren des Modells mit einer bestimmten Anzahl an Wiederholungen\n",
    "def evaluate_model(X, y, wiederholungen, s):\n",
    " # Vorbereiten der cross-validation-Prozedur\n",
    " crossvalidation = RepeatedKFold(n_splits=s, n_repeats=wiederholungen, random_state=1)\n",
    " # Modell erstellen\n",
    " modell = LogisticRegression()\n",
    " # Modell evaluieren\n",
    " ergebnis = cross_val_score(modell, X, y, scoring='accuracy', cv=crossvalidation, n_jobs=-1)\n",
    " return ergebnis\n",
    "\n",
    "wiederholungen = range(1,6)\n",
    "\n",
    "splits = range(2,11)\n",
    "for s in splits:\n",
    "    for w in wiederholungen:\n",
    "        scores = evaluate_model(features_all, target_all, w, s)\n",
    "        print(f\"Genauigkeit bei {s} Splits: {mean(scores)}\")\n",
    "    print(\"---------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bestimmen der Genauigkeit, Confusions-Matrix, R2-Score und Mean Squared Error (Train-Test-Split-Aufteilung von 10 bis 90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = range(1,10)\n",
    "for t in testSize:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_all, target_all, test_size=(t/10), random_state=42)\n",
    "    mymodel = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", penalty='l2', max_iter=5000)\n",
    "    mymodel.fit(X_train, y_train)\n",
    "\n",
    "    predicted_output = mymodel.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, predicted_output)\n",
    "    mse = mean_squared_error(y_test, predicted_output)\n",
    "    r2 = r2_score(y_test, predicted_output)\n",
    "    print(f\"Genauigkeit [bei einer Testgröße von {t*10}%]: {mymodel.score(X_test, y_test)}\")\n",
    "    print(f\"mean squared error: {mse}\")\n",
    "    print(f\"r2 score: {r2}\")\n",
    " \n",
    "    plt.figure(figsize= (7,7))\n",
    "    sns.heatmap(cm, yticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], xticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], annot=True, fmt='g')\n",
    "    plt.xlabel('Vorhergesagter Wert')\n",
    "    plt.ylabel('tatsächlicher Wert')\n",
    "    plt.show()\n",
    "    print(\"-------------------------------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genauere Betrachtung der logistischen Regression mit 10% Trainingsgröße und 90% Testgröße"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Klassen-Verteilung der Trainingsdaten: \")\n",
    "sns.countplot(x = y_train, data = features_all)\n",
    "plt.show()\n",
    "print(\"Klassen-Verteilung der Testdaten: \")\n",
    "sns.countplot(x = y_test, data = features_all)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_all, target_all, test_size=0.90, random_state=42)\n",
    "mymodel = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", penalty='l2', max_iter=5000)\n",
    "mymodel.fit(X_train, y_train)\n",
    "predicted_output = mymodel.predict(X_test)\n",
    "print(f\"Genauigkeit des Modells: {mymodel.score(X_test, y_test)}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, predicted_output)\n",
    "plt.figure(figsize= (7,7))\n",
    "sns.heatmap(cm, yticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], xticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], annot=True, fmt='g')\n",
    "plt.xlabel('Vorhergesagter Wert')\n",
    "plt.ylabel('tatsächlicher Wert')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predicted_output)\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logarithmische Koeffizienten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spalten = X_train.columns\n",
    "koeffizientenFürNiederlage = pd.Series(mymodel.coef_[0], spalten)\n",
    "koeffizientenFürUnentschieden = pd.Series(mymodel.coef_[1], spalten)\n",
    "koeffizientenFürSieg = pd.Series(mymodel.coef_[2], spalten)\n",
    "\n",
    "print(f\"Klasse: {mymodel.classes_}\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"logarithmische Koeffizienten:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse -1 (Niederlage):\")\n",
    "print(koeffizientenFürNiederlage)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 0 (Unentschieden):\")\n",
    "print(koeffizientenFürUnentschieden)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 1 (Sieg):\")\n",
    "print(koeffizientenFürSieg)\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zugehörige reguläre Koeffizienten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logarithmische zu regulären Werten umrechnen\n",
    "koeffizientenFürNiederlageRegulaer = pd.Series(np.exp(mymodel.coef_[0]), spalten)\n",
    "koeffizientenFürUnentschiedenRegulaer = pd.Series(np.exp(mymodel.coef_[1]), spalten)\n",
    "koeffizientenFürSiegRegulaer = pd.Series(np.exp(mymodel.coef_[2]), spalten)\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"reguläre Koeffizienten:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse -1 (Niederlage):\")\n",
    "print(koeffizientenFürNiederlageRegulaer)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 0 (Unentschieden):\")\n",
    "print(koeffizientenFürUnentschiedenRegulaer)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 1 (Sieg):\")\n",
    "print(koeffizientenFürSiegRegulaer)\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logarithmische Wahrscheinlichkeit, dass mithilfe dieses Features das Spielergebnis vorhergesagt werden kann\n",
    "print((\"logarithmische Wahrscheinlichkeit, dass ein Feature eine Niederlage vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürNiederlage.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"logarithmische Wahrscheinlichkeit\")\n",
    "plt.show()\n",
    "\n",
    "print((\"logarithmische Wahrscheinlichkeit, dass ein Feature ein Unentschieden vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürUnentschieden.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"logarithmische Wahrscheinlichkeit, dass ein Feature das Spielergebnis vorhersagen kann\")\n",
    "plt.show()\n",
    "\n",
    "print((\"logarithmische Wahrscheinlichkeit, dass ein Feature einen Sieg vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürSieg.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"logarithmische Wahrscheinlichkeit, dass ein Feature das Spielergebnis vorhersagen kann\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reguläre Wahrscheinlichkeit, dass mithilfe dieses Features das Spielergebnis vorhergesagt werden kann\n",
    "print((\"reguläre Wahrscheinlichkeit, dass ein Feature eine Niederlage vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürNiederlageRegulaer.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"reguläre Wahrscheinlichkeit\")\n",
    "plt.show()\n",
    "\n",
    "print((\"reguläre Wahrscheinlichkeit, dass ein Feature ein Unentschieden vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürUnentschiedenRegulaer.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"reguläre Wahrscheinlichkeit\")\n",
    "plt.show()\n",
    "\n",
    "print((\"reguläre Wahrscheinlichkeit, dass ein Feature einen Sieg vorhersagen kann\"))\n",
    "plt.figure(figsize= (4,4))\n",
    "koeffizientenFürSiegRegulaer.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"reguläre Wahrscheinlichkeit\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betrachtung des Ergebnisses bei einem Testsplit von 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versuch, ob bei weniger Trainingsdaten auch Unentschieden besser vorhergesagt werden können\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_all, target_all, test_size=0.99, random_state=42)\n",
    "mymodel = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", penalty='l2', max_iter=5000)\n",
    "mymodel.fit(X_train, y_train)\n",
    "predicted_output = mymodel.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, predicted_output)\n",
    "mse = mean_squared_error(y_test, predicted_output)\n",
    "r2 = r2_score(y_test, predicted_output)\n",
    "print(f\"Genauigkeit [bei einer Testgröße von 99%]: {mymodel.score(X_test, y_test)}\")\n",
    "print(f\"mean squared error: {mse}\")\n",
    "print(f\"r2 score: {r2}\")\n",
    "\n",
    "plt.figure(figsize= (7,7))\n",
    "sns.heatmap(cm, yticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], xticklabels=[\"Niederlage\", \"Unentschieden\", \"Sieg\"], annot=True, fmt='g')\n",
    "plt.xlabel('Vorhergesagter Wert')\n",
    "plt.ylabel('tatsächlicher Wert')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
