{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import export_graphviz\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, precision_score, recall_score, confusion_matrix, auc\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = sqlite3.connect('database.sqlite')\n",
    "\n",
    "player_data = pd.read_sql(\"SELECT id, player_api_id, player_name, birthday, height, weight FROM Player\", cnx)\n",
    "player_stats_data = pd.read_sql(\"SELECT id, player_api_id, date, overall_rating, potential, preferred_foot, attacking_work_rate, defensive_work_rate, crossing, finishing, heading_accuracy, short_passing, volleys, dribbling, curve, free_kick_accuracy, long_passing, ball_control, acceleration, sprint_speed, agility, reactions, shot_power, jumping, stamina, strength, long_shots, aggression, interceptions, positioning, vision, penalties, marking, standing_tackle, sliding_tackle, gk_diving, gk_handling, gk_kicking, gk_positioning, gk_reflexes FROM Player_Attributes\", cnx)\n",
    "match_data = pd.read_sql(\"SELECT id, country_id, league_id, season, stage, date, match_api_id, home_team_api_id, away_team_api_id, home_team_goal, away_team_goal, home_player_1, home_player_2, home_player_3, home_player_4, home_player_5, home_player_6, home_player_7, home_player_8, home_player_9, home_player_10, home_player_11, away_player_1, away_player_2, away_player_3, away_player_4, away_player_5, away_player_6, away_player_7, away_player_8, away_player_9, away_player_10, away_player_11, goal, shoton, shotoff, foulcommit, card, cross, corner, possession, B365H, B365D, B365A FROM Match\", cnx)\n",
    "league_data = pd.read_sql(\"SELECT id, country_id, name FROM League\", cnx)\n",
    "country_data = pd.read_sql(\"SELECT id, name FROM Country\", cnx)\n",
    "team_data = pd.read_sql(\"SELECT id, team_api_id, team_long_name, team_short_name FROM Team\", cnx)\n",
    "team_attributes_data = pd.read_sql(\"SELECT id, team_api_id, date, buildUpPlaySpeed, buildUpPlaySpeedClass, buildUpPlayDribbling, buildUpPlayDribblingClass, buildUpPlayPassing, buildUpPlayPassingClass, buildUpPlayPositioningClass, chanceCreationPassing, chanceCreationPassingClass, chanceCreationCrossing, chanceCreationCrossingClass, chanceCreationShooting, chanceCreationShooting, chanceCreationPositioningClass, defencePressure, defencePressureClass, defenceAggression, defenceAggressionClass, defenceTeamWidth, defenceTeamWidthClass, defenceDefenderLineClass FROM Team_Attributes\", cnx)\n",
    "\n",
    "\n",
    "def null_counts( dataframe ):\n",
    "    '''\n",
    "    Get percentage of empty values per column\n",
    "\n",
    "    Args:\n",
    "        dataframe: dataframe containing at least one column and value\n",
    "\n",
    "    Returns:\n",
    "        Returns nothing, prints percentages\n",
    "    '''\n",
    "    null_counts = dataframe.isnull().sum()\n",
    "    null_percents = null_counts / len(dataframe) * 100\n",
    "    print(null_percents)\n",
    "\n",
    "\n",
    "null_counts(player_data)\n",
    "null_counts(player_stats_data)\n",
    "null_counts(match_data)\n",
    "null_counts(league_data)\n",
    "null_counts(country_data)\n",
    "null_counts(team_data)\n",
    "null_counts(team_attributes_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenaufbereitung\n",
    "In diesem Code-Abschnitt werden die Daten bereinigt und für das maschinelle Lernen aufbereitet. Dazu werden die im vorherigen Abschnitt gesammelten Erkenntnisse zu den Anteilen von Leeren Werten je Spalte dazu genutzt, Spalten mit mangelnder Aussagekraft vollständig zu entfernen (`drop()`). Daraufhin wird sich außerdem der verbliebenen leeren Werte in allen Zeilen angenommen.\n",
    "\n",
    "## Spielerratings\n",
    "Die Tabelle Player_Attributes (Dtaframe `player_stats_data`) enthält Spiellerratings für alle Spieler zu verschiedenen Zeitpunkten. Dabei haben manche Spieler mehrere Ratings pro Jahr, andere nur ein Rating pro Jahr, wieder andere nur ein Rating in mehreren Jahren. Um diese unterschiedlichen Vorraussetzungen für alle Spieler auf ein Niveau zu bringen, werden mehrere unterjährige Ratings auf ein einzelnes gemittelt. Im folgenden wird dann für jeden Spieler das Rating aus dem benötigten Jahr verwendet. Gibt es kein Rating aus diesem Jahr, wird das naheliegenste Rating herangezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = match_data.drop(columns=[\"goal\", \"shoton\", \"shotoff\", \"foulcommit\", \"card\", \"cross\", \"corner\", \"possession\"], axis=1)\n",
    "team_attributes_data = team_attributes_data.drop(\"buildUpPlayDribbling\", axis=1)\n",
    "\n",
    "df_dropped = match_data.dropna()\n",
    "player_stats_data = player_stats_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_nearest_rating(date, player_api_id):\n",
    "    '''\n",
    "    Get player rating closest to the provided date\n",
    "\n",
    "    Args:\n",
    "        date: Date as int. (yyyymmdd)\n",
    "        player_api_id: player_api_id as int.\n",
    "\n",
    "    Returns:\n",
    "        Returns a new dataframe containing all player attributes for the nearest date.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: No data for provided player_api_id\n",
    "    '''\n",
    "    all_ratings_for_player: pd.DataFrame = player_stats_data.loc[player_stats_data[\"player_api_id\"] == player_api_id]\n",
    "    if (all_ratings_for_player.empty):\n",
    "        raise ValueError(f\"No data for provided player_api_id: {player_api_id}\")\n",
    "    if (len(all_ratings_for_player.index) == 1):\n",
    "        return all_ratings_for_player\n",
    "    intdate: pd.DataFrame = pd.DataFrame(columns=[\"date\"], dtype=np.int8)\n",
    "    for index, row in all_ratings_for_player.iterrows():\n",
    "        rowdate: str = row[\"date\"][:10]\n",
    "        rowdate = rowdate.replace('-', '')\n",
    "        intdate.loc[index] = int(rowdate)\n",
    "    intdate = intdate.set_index('date')\n",
    "    intdate.sort_index(inplace = True)\n",
    "    index = intdate.index.get_indexer([date], method=\"nearest\")\n",
    "    all_ratings_for_player.reset_index(inplace=True, drop=True)\n",
    "    return all_ratings_for_player.loc[index]\n",
    "\n",
    "def get_average_team_rating(dataframe, matchdate):\n",
    "    teamRating: int = 0\n",
    "    missingPlayers = 0\n",
    "    for name, series in dataframe.items():\n",
    "        try:\n",
    "            teamRating = teamRating + int(get_nearest_rating(date=matchdate, player_api_id=int(series.item()))[\"overall_rating\"])\n",
    "        except ValueError:\n",
    "            missingPlayers += 1  \n",
    "    return teamRating / (11 - missingPlayers)\n",
    "\n",
    "\n",
    "def get_player_height(player_api_id):\n",
    "    singleHeight = (player_data['height'].loc[player_data['player_api_id'] == player_api_id]).item()\n",
    "    if not singleHeight:\n",
    "        raise ValueError(f\"No height-value for provided player_api_id: {player_api_id}\")\n",
    "    else:\n",
    "        return singleHeight\n",
    "    \n",
    "\n",
    "def get_player_weight(player_api_id):\n",
    "    singleWeight = (player_data['weight'].loc[player_data['player_api_id'] == player_api_id]).item()\n",
    "    if not singleWeight:\n",
    "        raise ValueError(f\"No weight-value for provided player_api_id: {player_api_id}\")\n",
    "    else:\n",
    "        return singleWeight\n",
    "\n",
    "\n",
    "def get_player_age(player_api_id, date):\n",
    "    birthdate = (player_data['birthday'].loc[player_data['player_api_id'] == player_api_id]).item()\n",
    "    if not birthdate:\n",
    "        raise ValueError(f\"No age-value for provided player_api_id: {player_api_id}\")\n",
    "    else:\n",
    "        birthdate = birthdate[:10]\n",
    "        birthdate = birthdate.replace('-', '') \n",
    "\n",
    "        matchYear = str(date)[:4]\n",
    "        birthYear = str(birthdate)[:4]\n",
    "        matchMonth = str(date)[4:6]\n",
    "        birthMonth = str(birthdate)[4:6]\n",
    "\n",
    "        if int(matchMonth) < int(birthMonth):\n",
    "            return int(matchYear) - int(birthYear) - 1\n",
    "        elif int(matchMonth) == int(birthMonth):\n",
    "            matchDay = str(date)[6:8]\n",
    "            birthDay = str(birthdate)[6:8]\n",
    "            if(int(matchDay) < int(birthDay)):\n",
    "                return int(matchYear) - int(birthYear)\n",
    "            else:\n",
    "                return int(matchYear) - int(birthYear) \n",
    "        else:\n",
    "            return int(matchYear) - int(birthYear)\n",
    "\n",
    "\n",
    "def get_strong_foot(player_api_id):\n",
    "    \n",
    "    df_all_feet_player = player_stats_data['preferred_foot'].loc[player_stats_data['player_api_id'] == player_api_id]\n",
    "    df_all_feet_player.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    if df_all_feet_player.empty:\n",
    "        raise ValueError(f\"No preferred_foot-value for provided player_api_id: {player_api_id}\")\n",
    "    strongFoot = df_all_feet_player[0]\n",
    "    \n",
    "    if str(strongFoot) == 'right':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def set_label(dataframe):\n",
    "    homeGoals = dataframe['home_team_goal'].item()\n",
    "    awayGoals = dataframe['away_team_goal'].item()\n",
    "\n",
    "    if homeGoals > awayGoals:\n",
    "        return 'Win'\n",
    "    if homeGoals < awayGoals:\n",
    "        return 'Lose'\n",
    "    if homeGoals == awayGoals:\n",
    "        return 'Draw'\n",
    "\n",
    "\n",
    "def get_last_three_matches(team_api_id, date):\n",
    "    allHomeGamesOfTeam = match_data[['date', 'match_api_id', 'home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']].loc[match_data['home_team_api_id'] == team_api_id]\n",
    "    allAwayGamesOfTeam = match_data[['date', 'match_api_id', 'home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']].loc[match_data['away_team_api_id'] == team_api_id]\n",
    "    allGamesOfTeam = pd.concat([allHomeGamesOfTeam, allAwayGamesOfTeam],axis=0, join='inner')\n",
    "    allGamesOfTeam = allGamesOfTeam.sort_values(by=['date'])\n",
    "    for dateIndex, item in allGamesOfTeam['date'].iteritems():\n",
    "        itemdate: str = item[:10]\n",
    "        itemdate = itemdate.replace('-', '')\n",
    "        allGamesOfTeam.loc[dateIndex, 'date'] = int(itemdate)\n",
    "    allGamesOfTeam = allGamesOfTeam.reset_index()\n",
    "    indexOfMatch = allGamesOfTeam.loc[allGamesOfTeam['date'] == date].index\n",
    "    try:\n",
    "        lastMatch = allGamesOfTeam[['home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']].loc[(indexOfMatch - 1)]\n",
    "        lastMatchValue = get_match_value(lastMatch, team_api_id)\n",
    "    except:\n",
    "        lastMatchValue = 0\n",
    "    try:\n",
    "        secondLastMatch = allGamesOfTeam[['home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']].loc[(indexOfMatch - 2)]\n",
    "        secondLastMatchValue = get_match_value(secondLastMatch, team_api_id)\n",
    "    except:\n",
    "        secondLastMatchValue = 0\n",
    "    try:\n",
    "        thirdLastMatch = allGamesOfTeam[['home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']].loc[(indexOfMatch - 3)]\n",
    "        thirdLastMatchValue = get_match_value(thirdLastMatch, team_api_id)\n",
    "    except:\n",
    "        thirdLastMatchValue = 0\n",
    "    return (lastMatchValue + secondLastMatchValue + thirdLastMatchValue) \n",
    "\n",
    "\n",
    "\n",
    "def get_match_value(dataframe, team_api_id):\n",
    "    if (dataframe['home_team_api_id'].item() == team_api_id):\n",
    "        ownGoals = dataframe['home_team_goal'].item()\n",
    "        otherGoals = dataframe['away_team_goal'].item()\n",
    "    else:\n",
    "        ownGoals = dataframe['away_team_goal'].item()\n",
    "        otherGoals = dataframe['home_team_goal'].item()\n",
    "\n",
    "    if ownGoals > otherGoals:\n",
    "        return 3\n",
    "    if ownGoals < otherGoals:\n",
    "        return 0\n",
    "    if ownGoals == otherGoals:\n",
    "        return 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_dropped = df_dropped.assign(average_rating_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_rating_awayteam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_height_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_height_awayteam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_weight_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_weight_awayteam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_age_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(average_age_awayteam=np.NaN)\n",
    "df_dropped = df_dropped.assign(right_foot_percentage_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(right_foot_percentage_awayteam=np.NaN)\n",
    "df_dropped = df_dropped.assign(label_outcome=np.NaN)\n",
    "df_dropped = df_dropped.assign(last_three_matches_hometeam=np.NaN)\n",
    "df_dropped = df_dropped.assign(last_three_matches_awayteam=np.NaN)\n",
    "\n",
    "\n",
    "\n",
    "for index, match_api_id in df_dropped['match_api_id'].iteritems():\n",
    "    home_api_id = match_data['home_team_api_id'].loc[match_data['match_api_id'] == match_api_id].item()\n",
    "    away_api_id = match_data['away_team_api_id'].loc[match_data['match_api_id'] == match_api_id].item()\n",
    "\n",
    "\n",
    "    df_match = match_data.loc[match_data[\"match_api_id\"] == match_api_id]\n",
    "    df_match_home_player = df_match[[\"home_player_1\", \"home_player_2\", \"home_player_3\", \"home_player_4\", \"home_player_5\", \"home_player_6\", \"home_player_7\",\"home_player_8\", \"home_player_9\", \"home_player_10\", \"home_player_11\"]]\n",
    "    df_match_away_player = df_match[[\"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\", \"away_player_5\", \"away_player_6\", \"away_player_7\",\"away_player_8\", \"away_player_9\", \"away_player_10\", \"away_player_11\"]] \n",
    "\n",
    "    matchDate: str = df_match[\"date\"].item()\n",
    "    matchDate = matchDate[:10]\n",
    "    matchDate = matchDate.replace('-', '')\n",
    "    matchDateInt: np.int8 = int(matchDate)\n",
    "\n",
    "    average_team_rating_home = get_average_team_rating(dataframe=df_match_home_player, matchdate=matchDateInt)\n",
    "    average_team_rating_away = get_average_team_rating(dataframe=df_match_away_player, matchdate=matchDateInt)\n",
    "\n",
    "    lastThreeMatchesHome = get_last_three_matches(home_api_id, matchDateInt)\n",
    "    lastThreeMatchesAway = get_last_three_matches(away_api_id, matchDateInt)\n",
    "\n",
    "    teamHeightHome = 0\n",
    "    teamWeightHome = 0\n",
    "    teamAgeHome = 0\n",
    "    teamRightFootPercentageHome = 0\n",
    "    missingPlayerHeightHome = 0\n",
    "    missingPlayerWeightHome = 0\n",
    "    missingPlayerAgeHome = 0\n",
    "    missingPlayerStrongFootHome = 0\n",
    "\n",
    "    for name, series in df_match_home_player.items():\n",
    "        try:\n",
    "            teamHeightHome = teamHeightHome + int(get_player_height(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerHeightHome += 1  \n",
    "\n",
    "        try:\n",
    "            teamWeightHome = teamWeightHome + int(get_player_weight(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerWeightHome += 1  \n",
    "\n",
    "        try:\n",
    "            teamAgeHome = teamAgeHome + int(get_player_age(player_api_id=int(series.item()), date=matchDateInt))\n",
    "        except ValueError:\n",
    "            missingPlayerAgeHome += 1  \n",
    "\n",
    "        try:\n",
    "            teamRightFootPercentageHome = teamRightFootPercentageHome + int(get_strong_foot(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerStrongFootHome += 1  \n",
    "\n",
    "    teamHeightHome = teamHeightHome / (11 - missingPlayerHeightHome)\n",
    "    teamWeightHome = teamWeightHome / (11 - missingPlayerWeightHome)\n",
    "    teamAgeHome = teamAgeHome / (11 - missingPlayerWeightHome)\n",
    "    teamRightFootPercentageHome = teamRightFootPercentageHome / (11 - missingPlayerStrongFootHome)\n",
    "\n",
    "\n",
    "    teamHeightAway = 0\n",
    "    teamWeightAway = 0\n",
    "    teamAgeAway = 0\n",
    "    teamRightFootPercentageAway = 0\n",
    "    missingPlayerHeightAway = 0\n",
    "    missingPlayerWeightAway = 0\n",
    "    missingPlayerAgeAway = 0\n",
    "    missingPlayerStrongFootAway = 0\n",
    "\n",
    "    for name, series in df_match_away_player.items():\n",
    "        try:\n",
    "            teamHeightAway = teamHeightAway + int(get_player_height(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerHeightAway += 1  \n",
    "\n",
    "        try:\n",
    "            teamWeightAway = teamWeightAway + int(get_player_weight(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerWeightAway += 1  \n",
    "\n",
    "        try:\n",
    "            teamAgeAway = teamAgeAway + int(get_player_age(player_api_id=int(series.item()), date=matchDateInt))\n",
    "        except ValueError:\n",
    "            missingPlayerAgeAway += 1  \n",
    "\n",
    "        try:\n",
    "            teamRightFootPercentageAway = teamRightFootPercentageAway + int(get_strong_foot(player_api_id=int(series.item())))\n",
    "        except ValueError:\n",
    "            missingPlayerStrongFootAway += 1  \n",
    "\n",
    "    teamHeightAway = teamHeightAway / (11 - missingPlayerHeightAway)\n",
    "    teamWeightAway = teamWeightAway / (11 - missingPlayerWeightAway)\n",
    "    teamAgeAway = teamAgeAway / (11 - missingPlayerWeightAway)\n",
    "    teamRightFootPercentageAway = teamRightFootPercentageAway / (11 - missingPlayerStrongFootAway)\n",
    "    label_outcome = set_label(df_match)\n",
    "\n",
    "    df_dropped.loc[index,'average_rating_hometeam'] = average_team_rating_home\n",
    "    df_dropped.loc[index,'average_rating_awayteam'] = average_team_rating_away\n",
    "    df_dropped.loc[index,'average_height_hometeam'] = teamHeightHome\n",
    "    df_dropped.loc[index,'average_height_awayteam'] = teamHeightAway\n",
    "    df_dropped.loc[index,'average_weight_hometeam'] = teamWeightHome\n",
    "    df_dropped.loc[index,'average_weight_awayteam'] = teamWeightAway\n",
    "    df_dropped.loc[index,'average_age_hometeam'] = teamAgeHome\n",
    "    df_dropped.loc[index,'average_age_awayteam'] = teamAgeAway\n",
    "    df_dropped.loc[index,'right_foot_percentage_hometeam'] = teamRightFootPercentageHome\n",
    "    df_dropped.loc[index,'right_foot_percentage_awayteam'] = teamRightFootPercentageAway\n",
    "    df_dropped.loc[index,'label_outcome'] = label_outcome\n",
    "    df_dropped.loc[index,'last_three_matches_hometeam'] = lastThreeMatchesHome\n",
    "    df_dropped.loc[index,'last_three_matches_awayteam'] = lastThreeMatchesAway\n",
    "\n",
    "    #print(df_dropped)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenbanken erzeugen\n",
    "1. Eine Testdatenbank\n",
    "2. Eine Datenbank, die alle Daten vereint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_dropped\n",
    "\n",
    "\n",
    "# Datenbank mit allen Daten vereint\n",
    "conn = sqlite3.connect('neue_datenbank_all.db')\n",
    "df_test.to_sql('neue_tabelle_mit_allen_Daten', conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "# Nur die 500 ersten Zeilen von df_test nehmen\n",
    "df_top_500 = df_test.head(500)\n",
    "\n",
    "# Datenbank mit 500 Daten\n",
    "conn = sqlite3.connect('neue_datenbank_500.db')\n",
    "df_top_500.to_sql('neue_tabelle_mit_500_Daten', conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "\n",
    "# df_dropped wird mit der 500 DB gefüllt - gesamter Datensatz ist in df_test oder neue_datenbank_all.db\n",
    "\n",
    "# Verbindung zur SQLite-Datenbank herstellen\n",
    "conn = sqlite3.connect('neue_datenbank_500.db')\n",
    "\n",
    "# SQL-Abfrage ausführen und Ergebnis in ein Pandas-Dataframe laden\n",
    "df = pd.read_sql(\"SELECT * FROM neue_tabelle_mit_500_Daten\", conn)\n",
    "\n",
    "# Verbindung schließen\n",
    "conn.close()\n",
    "\n",
    "df_dropped = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Überprüfung ob jeder Spieler aus Match_data auch in der Spielerdatenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the player columns\n",
    "player_cols = ['home_player_1', 'home_player_2', 'home_player_3', 'home_player_4', 'home_player_5', 'home_player_6', 'home_player_7', 'home_player_8', 'home_player_9', 'home_player_10', 'home_player_11', 'away_player_1', 'away_player_2', 'away_player_3', 'away_player_4', 'away_player_5', 'away_player_6', 'away_player_7', 'away_player_8', 'away_player_9', 'away_player_10', 'away_player_11']\n",
    "    \n",
    "# Combine the columns horizontally\n",
    "combined_players = pd.concat([match_data[col] for col in player_cols])\n",
    "\n",
    "# Remove duplicates\n",
    "unique_players = combined_players.drop_duplicates()\n",
    "print(unique_players[0])\n",
    "\n",
    "# Check if every entry in the Series is in column A of the DataFrame\n",
    "mask = unique_players.isin(player_data['player_api_id'])\n",
    "\n",
    "# Replace the entries not in column A with a specified value\n",
    "unique_players[~mask] = -1\n",
    "\n",
    "# find the indices where the value is -1\n",
    "indices = unique_players.index[unique_players == -1]\n",
    "\n",
    "# count the number of occurrences of each unique value in the series\n",
    "counts = unique_players.value_counts()\n",
    "\n",
    "# print the indices & print the number of occurrences of -1\n",
    "print(counts[-1])\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindung zur SQLite-Datenbank herstellen\n",
    "conn = sqlite3.connect('neue_datenbank_500.db')\n",
    "\n",
    "# SQL-Abfrage ausführen und Ergebnis in ein Pandas-Dataframe laden\n",
    "df = pd.read_sql(\"SELECT * FROM neue_tabelle_mit_500_Daten\", conn)\n",
    "\n",
    "# Verbindung schließen\n",
    "conn.close()\n",
    "\n",
    "df_dropped = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert every non numeric column to a numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped['date_int'] = df_dropped['date'].apply(lambda x: int(x.replace('-', '').replace(' ', '').replace(':', '')))\n",
    "df_dropped = df_dropped.drop('date', axis=1)\n",
    "df_dropped = df_dropped.rename(columns={'date_int': 'date'})\n",
    "\n",
    "# create dictionary to map outcome labels to integer values\n",
    "outcome_map = {'Win': 1, 'Lose': -1, 'Draw': 0}\n",
    "\n",
    "# convert outcome labels to integer values\n",
    "df_dropped['label_outcome_int'] = df_dropped['label_outcome'].map(outcome_map)\n",
    "\n",
    "# replace original column with new integer column\n",
    "df_dropped['label_outcome'] = df_dropped['label_outcome_int']\n",
    "\n",
    "# drop temporary integer column\n",
    "df_dropped = df_dropped.drop('label_outcome_int', axis=1)\n",
    "\n",
    "\n",
    "#df_dropped['season'] = df_dropped['season'].str.split('/').str[0].astype(int)\n",
    "\n",
    "df_dropped.describe()\n",
    "df_dropped[\"date\"] = df_dropped[\"date\"].astype(int)\n",
    "df_dropped[\"label_outcome\"] = df_dropped[\"label_outcome\"].astype(int)\n",
    "\n",
    "print(df_dropped.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_temp = df_dropped\n",
    "conn = sqlite3.connect('neue_datenbank_numeric.db')\n",
    "df_temp.to_sql('neue_tabelle_mit_500_numerischen_Daten', conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindung zur SQLite-Datenbank herstellen\n",
    "conn = sqlite3.connect('neue_datenbank_all.db')\n",
    "\n",
    "# SQL-Abfrage ausführen und Ergebnis in ein Pandas-Dataframe laden\n",
    "df = pd.read_sql(\"SELECT * FROM neue_tabelle_mit_allen_Daten\", conn)\n",
    "\n",
    "# Verbindung schließen\n",
    "conn.close()\n",
    "\n",
    "df_dropped = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped['date_int'] = df_dropped['date'].apply(lambda x: int(x.replace('-', '').replace(' ', '').replace(':', '')))\n",
    "df_dropped = df_dropped.drop('date', axis=1)\n",
    "df_dropped = df_dropped.rename(columns={'date_int': 'date'})\n",
    "\n",
    "# create dictionary to map outcome labels to integer values\n",
    "outcome_map = {'Win': 1, 'Lose': -1, 'Draw': 0}\n",
    "\n",
    "# convert outcome labels to integer values\n",
    "df_dropped['label_outcome_int'] = df_dropped['label_outcome'].map(outcome_map)\n",
    "\n",
    "# replace original column with new integer column\n",
    "df_dropped['label_outcome'] = df_dropped['label_outcome_int']\n",
    "\n",
    "# drop temporary integer column\n",
    "df_dropped = df_dropped.drop('label_outcome_int', axis=1)\n",
    "\n",
    "\n",
    "#df_dropped['season'] = df_dropped['season'].str.split('/').str[0].astype(int)\n",
    "\n",
    "df_dropped.describe()\n",
    "df_dropped[\"date\"] = df_dropped[\"date\"].astype(int)\n",
    "df_dropped[\"label_outcome\"] = df_dropped[\"label_outcome\"].astype(int)\n",
    "\n",
    "print(df_dropped.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_temp = df_dropped\n",
    "conn = sqlite3.connect('neue_datenbank_numeric.db')\n",
    "df_temp.to_sql('neue_tabelle_mit_allen_numerischen_Daten', conn, if_exists='replace', index=False)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrelaitonsmatrix erstellt und in corr_matrix gespeichert => enthält Korrleationskoeffizienten zwischen allen möglichen Paaren\n",
    "corr_matrix = df_dropped.corr()\n",
    "\n",
    "# stack() wandelt Matrix in Series um, bei der jedes Element ein Paar von Spaltennamen und der Korrelationskoeffizient zwischen diesen Spalten ist\n",
    "# [abs(corr_matrix) > 0.9] reduziert die Werte auf nur Werte mit einem Wert über 0.9\n",
    "high_corr_pairs = corr_matrix.stack()[abs(corr_matrix.stack()) > 0.9]\n",
    "\n",
    "# Indizes der Serie werden zu Spaltennamen des Dataframe \n",
    "high_corr_pairs = high_corr_pairs.reset_index()\n",
    "\n",
    "# Spaltennamen des DataFrames umbenannt für bessere Lesbarkeit\n",
    "high_corr_pairs.columns = ['Column 1', 'Column 2', 'Correlation']\n",
    "\n",
    "print(high_corr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask for upper triangle\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Create heatmap with custom threshold\n",
    "plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(corr_matrix[(corr_matrix >= 0.3) | (corr_matrix <= -0.3)],\n",
    "            cmap='coolwarm', annot=True, fmt='.2f', mask=mask)\n",
    "\n",
    "# set the font color to black\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style({'font.family': 'serif', 'fontcolor': 'black'})\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # erstelle ein Dataframe für die Ergebnis von Chi2\n",
    "chi2_results_df = pd.DataFrame(columns=['Column 1', 'Column 2', 'Chi-Squared', 'P-Value'])\n",
    "\n",
    "# iteriert über jede Spalte des Dataframes\n",
    "for col in df_dropped.columns:\n",
    "    comparison_col = col\n",
    "\n",
    "    # iteriert über jede Spalte des Dataframes\n",
    "    for col in df_dropped.columns:\n",
    "\n",
    "        # überspringt den Schritt, wenn die Spalten die gleichen sind\n",
    "        if col == comparison_col:\n",
    "            continue\n",
    "\n",
    "        # erstellt eine Kontingenztabelle\n",
    "        contingency_table = pd.crosstab(df_dropped[comparison_col], df_dropped[col])\n",
    "\n",
    "        # führt chi2 aus und printed das Ergebnis\n",
    "        chi2, pval, dof, expected = chi2_contingency(contingency_table)\n",
    "                    #print(f\\Chi-squared test for columns '{comparison_col}' and '{col}': chi2={chi2}, pval={pval}\\)\n",
    "        chi2_results_df = chi2_results_df.append({'Column 1': comparison_col, 'Column 2': col, 'Chi-Squared': chi2, 'P-Value': pval}, ignore_index=True)\n",
    "\n",
    "    print(chi2_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# pivot the chi2_results_df to make a matrix\n",
    "heatmap_data = chi2_results_df.pivot(index='Column 1', columns='Column 2', values='P-Value')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "# create a heatmap\n",
    "sns.heatmap(heatmap_data, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "\n",
    "# set the font color to black\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style({'font.family': 'serif', 'fontcolor': 'black'})\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spalten mit hoher Korrelation löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df_dropped.drop('id', axis=1)\n",
    "df_dropped = df_dropped.drop('country_id', axis=1)\n",
    "df_dropped = df_dropped.drop('league_id', axis=1)\n",
    "df_dropped = df_dropped.drop('season', axis=1)\n",
    "df_dropped = df_dropped.drop('home_team_goal', axis=1)\n",
    "df_dropped = df_dropped.drop('away_team_goal', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weitere Berechnungen und Beziehungen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ist eine Auswirkung von Heimspiel oder Auswärtsspiel zu erkennen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zähle die Anzahl der Vorkommnisse von -1, 0 und 1 in der Spalte 'label_outcome'\n",
    "count = df_dropped['label_outcome'].value_counts()\n",
    "\n",
    "# Berechne den Prozentsatz, den jeder Wert auf das gesamte Dataframe bezieht\n",
    "percent = df_dropped['label_outcome'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Gib die Ergebnisse aus\n",
    "print(count)\n",
    "print(percent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie wirkt sich die Anzahl der Rechtsfüßler in einem Team auf den Ausgang des Spiels aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen eines Streudiagramms mit der Anzahl der rechtsfüßigen Spieler und dem Ausgang des Spiels\n",
    "plt.scatter(df_dropped['right_foot_percentage_hometeam'], df_dropped['label_outcome'])\n",
    "plt.xlabel('Anzahl der rechtsfüßigen Spieler')\n",
    "plt.ylabel('Ausgang des Spiels')\n",
    "\n",
    "# Hinzufügen der Linie\n",
    "x = df_dropped['right_foot_percentage_hometeam']\n",
    "y = df_dropped['label_outcome']\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "plt.plot(x, slope*x + intercept, color='red')\n",
    "\n",
    "# Ausgabe des Diagramms\n",
    "plt.show()\n",
    "\n",
    "# Erstelle ein Heatmap-Diagramm mit der Anzahl der rechtsfüßigen Spieler und dem Ausgang des Spiels\n",
    "sns.heatmap(pd.crosstab(df_dropped['right_foot_percentage_hometeam'], df['label_outcome'], normalize='index'), cmap='coolwarm')\n",
    "plt.xlabel('Ausgang des Spiels')\n",
    "plt.ylabel('Anzahl der rechtsfüßigen Spieler')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Trennung von Features und Zielvariablen\n",
    "features = df_dropped.drop('label_outcome', axis=1)\n",
    "target = df_dropped['label_outcome']\n",
    "\n",
    "\n",
    "# Definition des Modells\n",
    "model = LinearRegression()\n",
    "\n",
    "# Erstellung des RFE-Objekts mit 6 gewünschten Features (Ab 5 Features bleiben alle Metriken gleich)\n",
    "rfe = RFE(model, n_features_to_select=6)\n",
    "\n",
    "# Anpassung des RFE-Objekts an die Daten\n",
    "rfe.fit(features, target)\n",
    "\n",
    "# Ausgabe der ausgewählten Features\n",
    "selected_features = features.columns[rfe.support_]\n",
    "print(selected_features)\n",
    "\n",
    "# Trennung von Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features[selected_features], target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training des Modells\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage der Testdaten\n",
    "y_pred = model.predict(features_test)\n",
    "\n",
    "# Berechnung des R^2-Wertes\n",
    "r2 = r2_score(target_test, y_pred)\n",
    "print(\"R-squared value: {:.2f}\".format(r2))\n",
    "\n",
    "# Berechnung des Mean Squared Error\n",
    "mse = mean_squared_error(target_test, y_pred)\n",
    "print('MSE: {:.2f}'.format(mse))\n",
    "\n",
    "# Berechnung des Mean Absolute Error\n",
    "mae = mean_absolute_error(target_test, y_pred)\n",
    "print('MAE: {:.2f}'.format(mae))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Berechnung der Residuen\n",
    "residuals = target_test - y_pred\n",
    "\n",
    "# Erstellung des Residuenplots\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show() # Daten sollte zufällig um Null herum sein\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Erstellung des Verteilungsplots\n",
    "sns.histplot(target_test, kde=True, color='b', label='Actual Values')\n",
    "sns.histplot(y_pred, kde=True, color='r', label='Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Erstellung des Scatterplots\n",
    "plt.scatter(target_test, y_pred)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(model, features_test, target_test, n_repeats=10, random_state=42)\n",
    "importance = result.importances_mean\n",
    "plt.barh(selected_features, importance)\n",
    "plt.subplots_adjust(left=.3)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "coefs = model.coef_\n",
    "plt.barh(selected_features, coefs)\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.subplots_adjust(left=.3)\n",
    "plt.title(\"Feature Coefficients\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming you have split your data into features and target\n",
    "# and have selected the desired features for the model\n",
    "# you can create a dataframe with the selected features and the target variable\n",
    "data = pd.concat([features[selected_features], target], axis=1)\n",
    "\n",
    "# create a pairplot to visualize the relationships between the variables\n",
    "sns.pairplot(data, x_vars=selected_features, y_vars='label_outcome', height=5, aspect=1, kind='reg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model\n",
    "model.fit(features[selected_features], target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features[selected_features])\n",
    "\n",
    "# Create a regression plot\n",
    "sns.regplot(x=target, y=y_pred, ci=None)\n",
    "\n",
    "# Set the axis labels and title\n",
    "plt.xlabel('Actual Outcome')\n",
    "plt.ylabel('Predicted Outcome')\n",
    "plt.title('Linear Regression Model')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from random import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "# Entfernen von Zeilen, die NaN-Werte in der Zielvariablen enthalten\n",
    "df_dropped = df.dropna(subset=['label_outcome'])\n",
    "\n",
    "# Trennung von Features und Zielvariablen, Aussortieren von Features\n",
    "features = df_dropped.drop(['match_api_id', 'date', 'season', 'id', 'country_id', 'league_id', 'home_team_api_id', 'away_team_api_id', 'home_player_1', 'home_player_2', 'home_player_3', 'home_player_4', 'home_player_5', 'home_player_6', 'home_player_7','home_player_8', 'home_player_9', 'home_player_10', 'home_player_11', 'away_player_1', 'away_player_2', 'away_player_3', 'away_player_4', 'away_player_5', 'away_player_6', 'away_player_7','away_player_8', 'away_player_9', 'away_player_10', 'away_player_11', 'label_outcome', 'home_team_goal', 'away_team_goal'], axis=1)\n",
    "target = df_dropped['label_outcome']\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Test-Size 0.5, Genauigkeit: {accuracy}\")\n",
    "\n",
    "estimator = rf.estimators_[0]\n",
    "\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'tree.png')\n",
    "display(tree)\n",
    "\n",
    "#### Finde die besten Hyperparameter\n",
    "\n",
    "# Definition der Hyperparameter und ihrer möglichen Werte\n",
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20),\n",
    "              'min_samples_split': randint(2,10),\n",
    "              'min_samples_leaf': randint(1,10)}\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialisierung des Randomized Search CV Objekts\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions=param_dist,\n",
    "                                 n_iter=10,\n",
    "                                 cv=5,\n",
    "                                 random_state=42)\n",
    "\n",
    "# Suche nach den besten Hyperparametern auf den Trainingsdaten\n",
    "rand_search.fit(features_train, target_train)\n",
    "\n",
    "# Ausgabe der besten Hyperparameter und der Genauigkeit auf den Testdaten\n",
    "print(f\"Beste Hyperparameter: {rand_search.best_params_}\")\n",
    "print(f\"Genauigkeit auf Testdaten: {rand_search.score(features_test, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Test-Size 0.1, Genauigkeit: {accuracy}\")\n",
    "\n",
    "estimator = rf.estimators_[0]\n",
    "\n",
    "export_graphviz(estimator, out_file='tree01.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree01.dot', '-o', 'tree01.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'tree01.png')\n",
    "display(tree)\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42 ,max_depth=5)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Test-Size 0.1, Genauigkeit: {accuracy}\")\n",
    "\n",
    "estimator = rf.estimators_[0]\n",
    "\n",
    "export_graphviz(estimator, out_file='tree02.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree02.dot', '-o', 'tree02.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'tree02.png')\n",
    "display(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition der Hyperparameter und ihrer möglichen Werte\n",
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20),\n",
    "              'min_samples_split': randint(2,10),\n",
    "              'min_samples_leaf': randint(1,10)}\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialisierung des Randomized Search CV Objekts\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions=param_dist,\n",
    "                                 n_iter=10,\n",
    "                                 cv=5,\n",
    "                                 random_state=42)\n",
    "\n",
    "# Suche nach den besten Hyperparametern auf den Trainingsdaten\n",
    "rand_search.fit(features_train, target_train)\n",
    "\n",
    "# Ausgabe der besten Hyperparameter und der Genauigkeit auf den Testdaten\n",
    "print(f\"Beste Hyperparameter: {rand_search.best_params_}\")\n",
    "print(f\"Genauigkeit auf Testdaten: {rand_search.score(features_test, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best estimator and index\n",
    "best_rf = rand_search.best_estimator_\n",
    "best_index = rand_search.best_index_\n",
    "\n",
    "# Visualize the best tree\n",
    "estimator = best_rf.estimators_[best_index]\n",
    "\n",
    "export_graphviz(estimator, out_file='treebest.dot', \n",
    "                feature_names = features_train.columns,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'treebest.dot', '-o', 'treebest.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "tree = Image(filename = 'treebest.png')\n",
    "display(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage auf den Testdaten mit den besten Hyperparametern\n",
    "best_rf = rand_search.best_estimator_\n",
    "target_pred = best_rf.predict(features_test)\n",
    "\n",
    "# Berechnung des F1-Scores\n",
    "f1 = f1_score(target_test, target_pred, average='weighted')\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Berechnung der AUC\n",
    "target_proba = best_rf.predict_proba(features_test)\n",
    "auc = roc_auc_score(target_test, target_proba, multi_class='ovr')\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "# Berechnung der Precision\n",
    "precision = precision_score(target_test, target_pred, average='weighted', zero_division=1)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Berechnung des Recall\n",
    "recall = recall_score(target_test, target_pred, average='weighted', zero_division=1)\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit des Random Forest Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Berechnung der Feature Importance\n",
    "importance = best_rf.feature_importances_\n",
    "sorted_idx = importance.argsort()[::-1]\n",
    "print(\"Feature importance:\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{features_train.columns[i]}: {importance[i]}\")\n",
    "\n",
    "# Erstellung der Confusion Matrix\n",
    "target_pred = rf.predict(features_test)\n",
    "conf_mat = confusion_matrix(target_test, target_pred)\n",
    "\n",
    "# Plot der Confusion Matrix\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='g', \n",
    "            xticklabels=rf.classes_, yticklabels=rf.classes_)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the target variable\n",
    "target_bin = label_binarize(target_test, classes=['Win', 'Draw', 'Lose'])\n",
    "n_classes = target_bin.shape[1]\n",
    "\n",
    "# Compute the probabilities for each class\n",
    "target_proba = best_rf.predict_proba(features_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(target_bin[:, i], target_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(target_bin.ravel(), target_proba.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot the ROC curves for all classes and micro-average\n",
    "plt.figure()\n",
    "lw = 2\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve (area = %0.2f) for class %s' % (roc_auc[i], ['Win', 'Draw', 'Lose'][i]))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "# Add some visual enhancements\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports:\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import scale\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from scipy.stats import sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trennung von Features und Zielvariablen\n",
    "features = df_dropped.drop('label_outcome', axis=1)\n",
    "#features = df_dropped.drop([\"date\", \"match_api_id\", \"stage\", \"label_outcome\", \"home_team_api_id\", \"away_team_api_id\", \"home_player_1\", \"home_player_2\", \"home_player_3\", \"home_player_4\", \"home_player_5\", \"home_player_6\", \"home_player_7\",\"home_player_8\", \"home_player_9\", \"home_player_10\", \"home_player_11\", \"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\", \"away_player_5\", \"away_player_6\", \"away_player_7\",\"away_player_8\", \"away_player_9\", \"away_player_10\", \"away_player_11\"], axis=1)\n",
    "target = df_dropped['label_outcome']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_scores = pd.DataFrame() \n",
    "vif_scores[\"Attribute\"] = features.columns \n",
    "  \n",
    "# Errechnen des VIF für jedes Feature (Testen auf Multikollinarität -> liegt vor wenn VIF > 10)\n",
    "vif_scores[\"VIF Scores\"] = [variance_inflation_factor(features.values, i) for i in range(len(features.columns))] \n",
    "display(vif_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = df_dropped.drop([\"average_height_hometeam\", \"average_height_awayteam\", \"average_weight_hometeam\", \"average_weight_awayteam\", \"stage\", \"match_api_id\", \"label_outcome\", \"date\", \"home_team_api_id\", \"away_team_api_id\", \"home_player_1\", \"home_player_2\", \"home_player_3\", \"home_player_4\", \"home_player_5\", \"home_player_6\", \"home_player_7\",\"home_player_8\", \"home_player_9\", \"home_player_10\", \"home_player_11\", \"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\", \"away_player_5\", \"away_player_6\", \"away_player_7\",\"away_player_8\", \"away_player_9\", \"away_player_10\", \"away_player_11\"], axis=1)\n",
    "#features = (features-features.min())/(features.max()-features.min())\n",
    "\n",
    "\n",
    "vif_scores = pd.DataFrame() \n",
    "vif_scores[\"Attribute\"] = features.columns \n",
    "vif_scores[\"VIF Scores\"] = [variance_inflation_factor(features.values, i) for i in range(len(features.columns))] \n",
    "display(vif_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = features.drop([\"average_height_hometeam\", \"average_height_awayteam\", \"average_weight_hometeam\", \"average_weight_awayteam\"], axis=1) \n",
    "features = features.drop([\"average_height_hometeam\", \"average_height_awayteam\"], axis=1)\n",
    "#features = features.drop([\"B365A\", \"B365D\", \"B365H\"], axis=1)\n",
    "\n",
    "vif_scores = pd.DataFrame() \n",
    "vif_scores[\"Attribute\"] = features.columns \n",
    "# Errechnen des VIF für jedes Feature (Testen auf Multikollinarität -> liegt vor wenn VIF > 10)\n",
    "vif_scores[\"VIF Scores\"] = [variance_inflation_factor(features.values, i) for i in range(len(features.columns))] \n",
    "display(vif_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wie oft jede Kategorie vertreten ist\n",
    "print(\"Häufigkeit der einzelnen Kategorien: \")\n",
    "print(target.value_counts())\n",
    "\n",
    "# Häufigkeit der Zielvariable\n",
    "sn.countplot(x = target, data = features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluieren des Modells mit einer bestimmten Anzahl an Wiederholungen\n",
    "def evaluate_model(X, y, wiederholungen, s):\n",
    " # Vorbereiten der cross-validation-Prozedur\n",
    " crossvalidation = RepeatedKFold(n_splits=s, n_repeats=wiederholungen, random_state=1)\n",
    " # Modell erstellen\n",
    " modell = LogisticRegression()\n",
    " # Modell evaluieren\n",
    " ergebnis = cross_val_score(modell, X, y, scoring='accuracy', cv=crossvalidation, n_jobs=-1)\n",
    " return ergebnis\n",
    "\n",
    "\n",
    "wiederholungen = range(1,6)\n",
    "ergebnisse = list()\n",
    "\n",
    "splits = range(2,11)\n",
    "for s in splits:\n",
    "    for w in wiederholungen:\n",
    "        scores = evaluate_model(features, target, w, s)\n",
    "        print(f\"Genauigkeit bei {s} Splits: {mean(scores)}\")\n",
    "        print('%d: Mittelwert = %.4f; Standardabweichung = %.3f' % (w, mean(scores), sem(scores)))\n",
    "        ergebnisse.append(scores)\n",
    "    # organgene Linie zeigt den errechneten Median der Modellgenauigkeit für  die Anzahl an Wiederholungen (Wert, bei dem 50% der Werte unter und 50% der Werte über diesem liegen)\n",
    "    # grüne Dreieck zeigt das arithmetische Mittel an (den generellen Mittelwert aller Werte)\n",
    "    # wo die Überschneidungen zwischen der orangenen Linie und dem gründen Dreieck vorkommen, liegt bei diesem Wert an Wiederholungen wahrscheinlich eine gute symmetrische Verteilung vor\n",
    "    pyplot.boxplot(ergebnisse, labels=[str(w) for w in wiederholungen], showmeans=True)\n",
    "    pyplot.show()\n",
    "    ergebnisse = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "mymodel = linear_model.LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000)\n",
    "mymodel.fit(X_train, y_train)\n",
    "predicted_output = mymodel.predict(X_test)\n",
    "print(f\"Genauigkeit: {mymodel.score(X_test, y_test)}\")\n",
    "\n",
    "spalten = X_train.columns\n",
    "koeffizientenFürNiederlage = pd.Series(mymodel.coef_[0], spalten)\n",
    "koeffizientenFürUnentschieden = pd.Series(mymodel.coef_[1], spalten)\n",
    "koeffizientenFürSieg = pd.Series(mymodel.coef_[2], spalten)\n",
    "#interceptions = mymodel.intercept_\n",
    "\n",
    "print(f\"Klasse: {mymodel.classes_}\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"logarithmische Koeffizienten:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse -1:\")\n",
    "print(koeffizientenFürNiederlage)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 0:\")\n",
    "print(koeffizientenFürUnentschieden)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 1:\")\n",
    "print(koeffizientenFürSieg)\n",
    "print(\"-----------------------------------------------------\")\n",
    "#print(f\"Interceptions: {interceptions}\")\n",
    "#print(\"-----------------------------------------------------\")\n",
    "\n",
    "#logarithmische zu regulären Werten umrechnen\n",
    "koeffizientenFürNiederlageRegulaer = pd.Series(np.exp(mymodel.coef_[0]), spalten)\n",
    "koeffizientenFürUnentschiedenRegulaer = pd.Series(np.exp(mymodel.coef_[1]), spalten)\n",
    "koeffizientenFürSiegRegulaer = pd.Series(np.exp(mymodel.coef_[2]), spalten)\n",
    "#interceptionsRegulaer = np.exp(mymodel.intercept_)\n",
    "\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"reguläre Koeffizienten:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse -1:\")\n",
    "print(koeffizientenFürNiederlageRegulaer)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 0:\")\n",
    "print(koeffizientenFürUnentschiedenRegulaer)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Koeffizienten für Klasse 1:\")\n",
    "print(koeffizientenFürSiegRegulaer)\n",
    "print(\"-----------------------------------------------------\")\n",
    "#print(f\"Interceptions: {interceptionsRegulaer}\")\n",
    "#print(\"-----------------------------------------------------\")\n",
    "\n",
    "\n",
    "#logarithmische Wahrscheinlichkeit, dass mithilfe dieses Features das Spielergebnis vorhergesagt werden kann\n",
    "plt.figure(figsize= (8,10))\n",
    "koeffizientenFürNiederlage.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"logarithmische Wahrscheinlichkeit, dass ein Feature das Spielergebnis vorhersagen kann\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (8,10))\n",
    "koeffizientenFürUnentschieden.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"logarithmische Wahrscheinlichkeit, dass ein Feature das Spielergebnis vorhersagen kann\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (8,10))\n",
    "koeffizientenFürSieg.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"logarithmische Wahrscheinlichkeit, dass ein Feature das Spielergebnis vorhersagen kann\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (8,10))\n",
    "koeffizientenFürNiederlageRegulaer.sort_values().plot.barh()\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlabel(\"Wahrscheinlichkeit, dass ein Feature das Spielergebnis vorhersagen kann\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(mymodel, features, target, scoring=\"accuracy\", cv=cv, n_jobs=-1)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "\n",
    "# wie die regulären Werte zu interpretieren sind: \n",
    "\n",
    "# Wenn man bei der Klasse Niederlage einen regulären Koeffizienten von 1,046 hat und nun vom Overall_Rating 1 abzieht, \n",
    "# dann steigt die Wahrscheinlichkeit, dass das Team verliert um 4,6%\n",
    "\n",
    "# Wenn man bei der Klasse Niederlage einen regulären Koeffizienten von 0,964 hat und vom Overall_Rating 1 abzieht,\n",
    "# dann sinkt die Wahrscheinlichkeit, dass das Team verliert um 4,6%\n",
    "\n",
    "\n",
    "\n",
    "# Odds Ratio (die regulären Koeffizienten) geben an, um wie viel größer die Chance auf das Ergebnis (-1, 0 oder 1) ist, bei einer Stufe höher auf der \n",
    "# Prädiktor-Variable (Wenn das Heimteam zum Beispiel ein Tor schießt)\n",
    "# Wert von 1 -> gleiches Chancenverhältnis\n",
    "# Wert von unter 1 -> Chancenverhältnis nimmt ab\n",
    "# Wert von über 1 -> Chancenverhältnis nimmt zu\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "sn.countplot(x = y_train, data = features)\n",
    "plt.show()\n",
    "sn.countplot(x = y_test, data = features)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "#multiklassen-Klassifizierung notwendig, da wir nicht nur Sieg und Niederlage haben, sondern auch noch Unentschieden\n",
    "# 1. Aufteilen der Daten in Training- und Testdaten\n",
    "\n",
    "testSize = range(2,9)\n",
    "for t in testSize:\n",
    "    print(f\"Genauigkeit bei einer Testgröße von {t/10}:\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=(t/10), random_state=42)\n",
    "\n",
    "    mymodel = linear_model.LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=3000)\n",
    "    mymodel.fit(X_train, y_train)\n",
    "\n",
    "    predicted_output = mymodel.predict(X_test)\n",
    "    #print(f\"Genauigkeit: {mymodel.score(X_test, y_test)}\")\n",
    "    print(f\"Genauigkeit: {mymodel.score(X_test, y_test)}\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, predicted_output)\n",
    "    mse = mean_squared_error(y_test, predicted_output)\n",
    "    r2 = r2_score(y_test, predicted_output)\n",
    "    print(f\"mean squared error: {mse}\")\n",
    "    print(f\"r2 score (Wie viel Prozent der Varianz werden erklärt?): {r2}\")\n",
    " \n",
    "    plt.figure(figsize= (6,6))\n",
    "    sn.heatmap(cm, annot=True)\n",
    "    plt.xlabel('Vorhergesagter Wert')\n",
    "    plt.ylabel('tatsächlicher Wert')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswirkung von home_team_rating auf away_team_goal\n",
    "#x = features['average_rating_hometeam']\n",
    "#y = features['away_team_goal']\n",
    "\n",
    "#plt.scatter(x, y)  \n",
    "#plt.plot(np.unique(x),np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = 'green')  \n",
    "#print(\"Auswirkungen des average_rating_hometeam auf die Anzahl an Gegentoren (Aus Sicht des Heimteams):\")\n",
    "#plt.xlabel(\"Rating des Heimteams\")\n",
    "#plt.ylabel(\"Anzahl an Gegentoren (aus Sicht des Heimteams)\")\n",
    "#plt.show()\n",
    "\n",
    "# Auswirkung von home_team_rating auf label_outcome\n",
    "x = features['average_rating_hometeam']\n",
    "y = target\n",
    "\n",
    "plt.scatter(x, y)  \n",
    "plt.plot(np.unique(x),np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = 'green')  \n",
    "print(\"Auswirkungen des average_rating_hometeam auf den Spielausgang (Aus Sicht des Heimteams):\")\n",
    "plt.xlabel(\"Rating des Heimteams\")\n",
    "plt.ylabel(\"Spielausgang (aus Sicht des Heimteams)\")\n",
    "plt.show()\n",
    "\n",
    "# Auswirkung von away_team_rating auf label_outcome\n",
    "x = features['average_rating_awayteam']\n",
    "y = target\n",
    "\n",
    "plt.scatter(x, y)  \n",
    "plt.plot(np.unique(x),np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = 'green')  \n",
    "print(\"Auswirkungen des average_rating_awayteam auf den Spielausgang (Aus Sicht des Heimteams):\")\n",
    "plt.xlabel(\"Rating des Auswärtsteams\")\n",
    "plt.ylabel(\"Spielausgang (aus Sicht des Heimteams)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
