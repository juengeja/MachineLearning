{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               0.0\n",
      "player_api_id    0.0\n",
      "player_name      0.0\n",
      "birthday         0.0\n",
      "height           0.0\n",
      "weight           0.0\n",
      "dtype: float64\n",
      "id                     0.000000\n",
      "player_api_id          0.000000\n",
      "date                   0.000000\n",
      "overall_rating         0.454402\n",
      "potential              0.454402\n",
      "preferred_foot         0.454402\n",
      "attacking_work_rate    1.755645\n",
      "defensive_work_rate    0.454402\n",
      "crossing               0.454402\n",
      "finishing              0.454402\n",
      "heading_accuracy       0.454402\n",
      "short_passing          0.454402\n",
      "volleys                1.474633\n",
      "dribbling              0.454402\n",
      "curve                  1.474633\n",
      "free_kick_accuracy     0.454402\n",
      "long_passing           0.454402\n",
      "ball_control           0.454402\n",
      "acceleration           0.454402\n",
      "sprint_speed           0.454402\n",
      "agility                1.474633\n",
      "reactions              0.454402\n",
      "shot_power             0.454402\n",
      "jumping                1.474633\n",
      "stamina                0.454402\n",
      "strength               0.454402\n",
      "long_shots             0.454402\n",
      "aggression             0.454402\n",
      "interceptions          0.454402\n",
      "positioning            0.454402\n",
      "vision                 1.474633\n",
      "penalties              0.454402\n",
      "marking                0.454402\n",
      "standing_tackle        0.454402\n",
      "sliding_tackle         1.474633\n",
      "gk_diving              0.454402\n",
      "gk_handling            0.454402\n",
      "gk_kicking             0.454402\n",
      "gk_positioning         0.454402\n",
      "gk_reflexes            0.454402\n",
      "dtype: float64\n",
      "id                   0.000000\n",
      "country_id           0.000000\n",
      "league_id            0.000000\n",
      "season               0.000000\n",
      "stage                0.000000\n",
      "date                 0.000000\n",
      "match_api_id         0.000000\n",
      "home_team_api_id     0.000000\n",
      "away_team_api_id     0.000000\n",
      "home_team_goal       0.000000\n",
      "away_team_goal       0.000000\n",
      "home_player_1        4.711498\n",
      "home_player_2        5.061781\n",
      "home_player_3        4.930906\n",
      "home_player_4        5.092575\n",
      "home_player_5        5.065630\n",
      "home_player_6        5.100273\n",
      "home_player_7        4.723046\n",
      "home_player_8        5.038685\n",
      "home_player_9        4.900112\n",
      "home_player_10       5.527541\n",
      "home_player_11       5.985604\n",
      "away_player_1        4.749990\n",
      "away_player_2        4.919358\n",
      "away_player_3        4.977097\n",
      "away_player_4        5.084876\n",
      "away_player_5        5.138766\n",
      "away_player_6        5.054082\n",
      "away_player_7        4.753840\n",
      "away_player_8        5.161862\n",
      "away_player_9        5.111821\n",
      "away_player_10       5.546788\n",
      "away_player_11       5.981754\n",
      "goal                45.275030\n",
      "shoton              45.275030\n",
      "shotoff             45.275030\n",
      "foulcommit          45.275030\n",
      "card                45.275030\n",
      "cross               45.275030\n",
      "corner              45.275030\n",
      "possession          45.275030\n",
      "B365H               13.037453\n",
      "B365D               13.037453\n",
      "B365A               13.037453\n",
      "dtype: float64\n",
      "id            0.0\n",
      "country_id    0.0\n",
      "name          0.0\n",
      "dtype: float64\n",
      "id      0.0\n",
      "name    0.0\n",
      "dtype: float64\n",
      "id                 0.0\n",
      "team_api_id        0.0\n",
      "team_long_name     0.0\n",
      "team_short_name    0.0\n",
      "dtype: float64\n",
      "id                                 0.000000\n",
      "team_api_id                        0.000000\n",
      "date                               0.000000\n",
      "buildUpPlaySpeed                   0.000000\n",
      "buildUpPlaySpeedClass              0.000000\n",
      "buildUpPlayDribbling              66.460905\n",
      "buildUpPlayDribblingClass          0.000000\n",
      "buildUpPlayPassing                 0.000000\n",
      "buildUpPlayPassingClass            0.000000\n",
      "buildUpPlayPositioningClass        0.000000\n",
      "chanceCreationPassing              0.000000\n",
      "chanceCreationPassingClass         0.000000\n",
      "chanceCreationCrossing             0.000000\n",
      "chanceCreationCrossingClass        0.000000\n",
      "chanceCreationShooting             0.000000\n",
      "chanceCreationShooting             0.000000\n",
      "chanceCreationPositioningClass     0.000000\n",
      "defencePressure                    0.000000\n",
      "defencePressureClass               0.000000\n",
      "defenceAggression                  0.000000\n",
      "defenceAggressionClass             0.000000\n",
      "defenceTeamWidth                   0.000000\n",
      "defenceTeamWidthClass              0.000000\n",
      "defenceDefenderLineClass           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cnx = sqlite3.connect('database.sqlite')\n",
    "\n",
    "player_data = pd.read_sql(\"SELECT id, player_api_id, player_name, birthday, height, weight FROM Player\", cnx)\n",
    "player_stats_data = pd.read_sql(\"SELECT id, player_api_id, date, overall_rating, potential, preferred_foot, attacking_work_rate, defensive_work_rate, crossing, finishing, heading_accuracy, short_passing, volleys, dribbling, curve, free_kick_accuracy, long_passing, ball_control, acceleration, sprint_speed, agility, reactions, shot_power, jumping, stamina, strength, long_shots, aggression, interceptions, positioning, vision, penalties, marking, standing_tackle, sliding_tackle, gk_diving, gk_handling, gk_kicking, gk_positioning, gk_reflexes FROM Player_Attributes\", cnx)\n",
    "match_data = pd.read_sql(\"SELECT id, country_id, league_id, season, stage, date, match_api_id, home_team_api_id, away_team_api_id, home_team_goal, away_team_goal, home_player_1, home_player_2, home_player_3, home_player_4, home_player_5, home_player_6, home_player_7, home_player_8, home_player_9, home_player_10, home_player_11, away_player_1, away_player_2, away_player_3, away_player_4, away_player_5, away_player_6, away_player_7, away_player_8, away_player_9, away_player_10, away_player_11, goal, shoton, shotoff, foulcommit, card, cross, corner, possession, B365H, B365D, B365A FROM Match\", cnx)\n",
    "league_data = pd.read_sql(\"SELECT id, country_id, name FROM League\", cnx)\n",
    "country_data = pd.read_sql(\"SELECT id, name FROM Country\", cnx)\n",
    "team_data = pd.read_sql(\"SELECT id, team_api_id, team_long_name, team_short_name FROM Team\", cnx)\n",
    "team_attributes_data = pd.read_sql(\"SELECT id, team_api_id, date, buildUpPlaySpeed, buildUpPlaySpeedClass, buildUpPlayDribbling, buildUpPlayDribblingClass, buildUpPlayPassing, buildUpPlayPassingClass, buildUpPlayPositioningClass, chanceCreationPassing, chanceCreationPassingClass, chanceCreationCrossing, chanceCreationCrossingClass, chanceCreationShooting, chanceCreationShooting, chanceCreationPositioningClass, defencePressure, defencePressureClass, defenceAggression, defenceAggressionClass, defenceTeamWidth, defenceTeamWidthClass, defenceDefenderLineClass FROM Team_Attributes\", cnx)\n",
    "\n",
    "\n",
    "def null_counts( dataframe ):\n",
    "    '''\n",
    "    Get percentage of empty values per column\n",
    "\n",
    "    Args:\n",
    "        dataframe: dataframe containing at least one column and value\n",
    "\n",
    "    Returns:\n",
    "        Returns nothing, prints percentages\n",
    "    '''\n",
    "    null_counts = dataframe.isnull().sum()\n",
    "    null_percents = null_counts / len(dataframe) * 100\n",
    "    print(null_percents)\n",
    "\n",
    "\n",
    "null_counts(player_data)\n",
    "null_counts(player_stats_data)\n",
    "null_counts(match_data)\n",
    "null_counts(league_data)\n",
    "null_counts(country_data)\n",
    "null_counts(team_data)\n",
    "null_counts(team_attributes_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenaufbereitung\n",
    "In diesem Code-Abschnitt werden die Daten bereinigt und für das maschinelle Lernen aufbereitet. Dazu werden die im vorherigen Abschnitt gesammelten Erkenntnisse zu den Anteilen von Leeren Werten je Spalte dazu genutzt, Spalten mit mangelnder Aussagekraft vollständig zu entfernen (`drop()`). Daraufhin wird sich außerdem der verbliebenen leeren Werte in allen Zeilen angenommen.\n",
    "\n",
    "## Spielerratings\n",
    "Die Tabelle Player_Attributes (Dtaframe `player_stats_data`) enthält Spiellerratings für alle Spieler zu verschiedenen Zeitpunkten. Dabei haben manche Spieler mehrere Ratings pro Jahr, andere nur ein Rating pro Jahr, wieder andere nur ein Rating in mehreren Jahren. Um diese unterschiedlichen Vorraussetzungen für alle Spieler auf ein Niveau zu bringen, werden mehrere unterjährige Ratings auf ein einzelnes gemittelt. Im folgenden wird dann für jeden Spieler das Rating aus dem benötigten Jahr verwendet. Gibt es kein Rating aus diesem Jahr, wird das naheliegenste Rating herangezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = match_data.drop(columns=[\"goal\", \"shoton\", \"shotoff\", \"foulcommit\", \"card\", \"cross\", \"corner\", \"possession\"], axis=1)\n",
    "team_attributes_data = team_attributes_data.drop(\"buildUpPlayDribbling\", axis=1)\n",
    "\n",
    "df_dropped = match_data.dropna()\n",
    "player_stats_data = player_stats_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81.9090909090909, 73.44444444444444)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_nearest_rating(date, player_api_id):\n",
    "    '''\n",
    "    Get player rating closest to the provided date\n",
    "\n",
    "    Args:\n",
    "        date: Date as int. (yyyymmdd)\n",
    "        player_api_id: player_api_id as int.\n",
    "\n",
    "    Returns:\n",
    "        Returns a new dataframe containing all player attributes for the nearest date.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: No data for provided player_api_id\n",
    "    '''\n",
    "    all_ratings_for_player: pd.DataFrame = player_stats_data.loc[player_stats_data[\"player_api_id\"] == player_api_id]\n",
    "    if (all_ratings_for_player.empty):\n",
    "        raise ValueError(f\"No data for provided player_api_id: {player_api_id}\")\n",
    "    if (len(all_ratings_for_player.index) == 1):\n",
    "        return all_ratings_for_player\n",
    "    intdate: pd.DataFrame = pd.DataFrame(columns=[\"date\"], dtype=np.int8)\n",
    "    for index, row in all_ratings_for_player.iterrows():\n",
    "        rowdate: str = row[\"date\"][:10]\n",
    "        rowdate = rowdate.replace('-', '')\n",
    "        intdate.loc[index] = int(rowdate)\n",
    "    intdate = intdate.set_index('date')\n",
    "    intdate.sort_index(inplace = True)\n",
    "    index = intdate.index.get_indexer([date], method=\"nearest\")\n",
    "    all_ratings_for_player.reset_index(inplace=True, drop=True)\n",
    "    return all_ratings_for_player.loc[index]\n",
    "\n",
    "def get_average_team_rating(team_api_id, match_api_id):\n",
    "    df_match = match_data.loc[match_data[\"match_api_id\"] == match_api_id]\n",
    "    matchDate: str = df_match[\"date\"].item()\n",
    "    if ((df_match[\"home_team_api_id\"].item() == team_api_id).item()):\n",
    "        df_match = df_match[[\"home_player_1\", \"home_player_2\", \"home_player_3\", \"home_player_4\", \"home_player_5\", \"home_player_6\", \"home_player_7\",\"home_player_8\", \"home_player_9\", \"home_player_10\", \"home_player_11\"]]\n",
    "    elif ((df_match[\"away_team_api_id\"].item() == team_api_id).item()):\n",
    "        df_match = df_match[[\"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\", \"away_player_5\", \"away_player_6\", \"away_player_7\",\"away_player_8\", \"away_player_9\", \"away_player_10\", \"away_player_11\"]] \n",
    "    else:\n",
    "        raise ValueError(\"\") #TODO\n",
    "    \n",
    "    matchDate = matchDate[:10]\n",
    "    matchDate = matchDate.replace('-', '')\n",
    "    matchDateInt: np.int8 = int(matchDate)\n",
    "\n",
    "    teamRating: int = 0\n",
    "    missingPlayers = 0\n",
    "    for name, series in df_match.items():\n",
    "        try:\n",
    "            teamRating = teamRating + get_nearest_rating(date=matchDateInt, player_api_id=int(series.item()))[\"overall_rating\"]\n",
    "        except ValueError:\n",
    "            missingPlayers += 1\n",
    "    \n",
    "    return teamRating / (11 - missingPlayers)\n",
    "\n",
    "def get_match_ratings(match_api_id):\n",
    "    df_match = match_data.loc[match_data[\"match_api_id\"] == match_api_id]\n",
    "    return get_average_team_rating(team_api_id=df_match[\"home_team_api_id\"], match_api_id=match_api_id).item(), get_average_team_rating(team_api_id=df_match[\"away_team_api_id\"], match_api_id=match_api_id).item()\n",
    "\n",
    "get_match_ratings(530240)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Überprüfung ob jeder Spieler aus Match_data auch in der Spielerdatenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "1\n",
      "Int64Index([0], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Select the player columns\n",
    "player_cols = ['home_player_1', 'home_player_2', 'home_player_3', 'home_player_4', 'home_player_5', 'home_player_6', 'home_player_7', 'home_player_8', 'home_player_9', 'home_player_10', 'home_player_11', 'away_player_1', 'away_player_2', 'away_player_3', 'away_player_4', 'away_player_5', 'away_player_6', 'away_player_7', 'away_player_8', 'away_player_9', 'away_player_10', 'away_player_11']\n",
    "    \n",
    "# Combine the columns horizontally\n",
    "combined_players = pd.concat([match_data[col] for col in player_cols])\n",
    "\n",
    "# Remove duplicates\n",
    "unique_players = combined_players.drop_duplicates()\n",
    "print(unique_players[0])\n",
    "\n",
    "# Check if every entry in the Series is in column A of the DataFrame\n",
    "mask = unique_players.isin(player_data['player_api_id'])\n",
    "\n",
    "# Replace the entries not in column A with a specified value\n",
    "unique_players[~mask] = -1\n",
    "\n",
    "# find the indices where the value is -1\n",
    "indices = unique_players.index[unique_players == -1]\n",
    "\n",
    "# count the number of occurrences of each unique value in the series\n",
    "counts = unique_players.value_counts()\n",
    "\n",
    "# print the indices & print the number of occurrences of -1\n",
    "print(counts[-1])\n",
    "print(indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hier muss noch die Zusammenführung der Daten geschehen in ein Dataframe df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Column 1, Column 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Korrelaitonsmatrix erstellt und in corr_matrix gespeichert => enthält Korrleationskoeffizienten zwischen allen möglichen Paaren\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# stack() wandelt Matrix in Series um, bei der jedes Element ein Paar von Spaltennamen und der Korrelationskoeffizient zwischen diesen Spalten ist\n",
    "# [abs(corr_matrix) > 0.9] reduziert die Werte auf nur Werte mit einem Wert über 0.9\n",
    "high_corr_pairs = corr_matrix.stack()[abs(corr_matrix.stack()) > 0.9]\n",
    "\n",
    "#Weitere Möglichkeit, falls das oben nicht geht --> Löschen, wenn nicht gebraucht \n",
    "#high_corr_pairs = corr_matrix.stack().where(abs(corr_matrix) > 0.9).dropna()\n",
    "\n",
    "\n",
    "# Indizes der Serie werden zu Spaltennamen des Dataframe \n",
    "high_corr_pairs = high_corr_pairs.reset_index()\n",
    "\n",
    "# Spaltennamen des DataFrames umbenannt für bessere Lesbarkeit\n",
    "high_corr_pairs.columns = ['Column 1', 'Column 2', 'Correlation']\n",
    "\n",
    "print(high_corr_pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Column 1, Column 2, Chi-Squared, P-Value]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    " # erstelle ein Dataframe für die Ergebnis von Chi2\n",
    "chi2_results_df = pd.DataFrame(columns=['Column 1', 'Column 2', 'Chi-Squared', 'P-Value'])\n",
    "\n",
    "# iteriert über jede Spalte des Dataframes\n",
    "for col in df.columns:\n",
    "    comparison_col = col\n",
    "\n",
    "    # iteriert über jede Spalte des Dataframes\n",
    "    for col in df.columns:\n",
    "\n",
    "        # überspringt den Schritt, wenn die Spalten die gleichen sind\n",
    "        if col == comparison_col:\n",
    "            continue\n",
    "\n",
    "        # erstellt eine Kontingenztabelle\n",
    "        contingency_table = pd.crosstab(df[comparison_col], df[col])\n",
    "\n",
    "        # führt chi2 aus und printed das Ergebnis\n",
    "        chi2, pval, dof, expected = chi2_contingency(contingency_table)\n",
    "                    #print(f\\Chi-squared test for columns '{comparison_col}' and '{col}': chi2={chi2}, pval={pval}\\)\n",
    "        chi2_results_df = chi2_results_df.append({'Column 1': comparison_col, 'Column 2': col, 'Chi-Squared': chi2, 'P-Value': pval}, ignore_index=True)\n",
    "\n",
    "print(chi2_results_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Was machen wir mit dem Ergebnis\n",
    "\n",
    "#Wrapper Methode\n",
    "Sucht die beste Untergruppe von Features für ein Mdoell, indem eine Modell-basierte Bewertung der Feature-Untergruppen durchführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['whoWon'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Trennung von Features und Zielvariablen\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m features \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mwhoWon\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m target \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mwhoWon\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[39m# Definition des Modells\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5400\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5401\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5402\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5403\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5404\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5405\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5406\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5407\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['whoWon'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Trennung von Features und Zielvariablen\n",
    "features = df.drop('whoWon', axis=1)\n",
    "target = df['whoWon']\n",
    "\n",
    "# Definition des Modells\n",
    "model = LinearRegression()\n",
    "\n",
    "# Erstellung des RFE-Objekts mit 10 gewünschten Features\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "\n",
    "# Anpassung des RFE-Objekts an die Daten\n",
    "rfe.fit(features, target)\n",
    "\n",
    "# Ausgabe der ausgewählten Features\n",
    "selected_features = features.columns[rfe.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trennung von Features und Zielvariablen\n",
    "features = df.drop('whoWon', axis=1)\n",
    "target = df['whoWon']\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Genauigkeit: {accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trennung von Features und Zielvariablen\n",
    "features = df.drop('whoWon', axis=1)\n",
    "target = df['whoWon']\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definition des logistischen Regressionsmodells\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "lr.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = lr.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Genauigkeit: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
