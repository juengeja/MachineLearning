{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               0.0\n",
      "player_api_id    0.0\n",
      "player_name      0.0\n",
      "birthday         0.0\n",
      "height           0.0\n",
      "weight           0.0\n",
      "dtype: float64\n",
      "id                     0.000000\n",
      "player_api_id          0.000000\n",
      "date                   0.000000\n",
      "overall_rating         0.454402\n",
      "potential              0.454402\n",
      "preferred_foot         0.454402\n",
      "attacking_work_rate    1.755645\n",
      "defensive_work_rate    0.454402\n",
      "crossing               0.454402\n",
      "finishing              0.454402\n",
      "heading_accuracy       0.454402\n",
      "short_passing          0.454402\n",
      "volleys                1.474633\n",
      "dribbling              0.454402\n",
      "curve                  1.474633\n",
      "free_kick_accuracy     0.454402\n",
      "long_passing           0.454402\n",
      "ball_control           0.454402\n",
      "acceleration           0.454402\n",
      "sprint_speed           0.454402\n",
      "agility                1.474633\n",
      "reactions              0.454402\n",
      "shot_power             0.454402\n",
      "jumping                1.474633\n",
      "stamina                0.454402\n",
      "strength               0.454402\n",
      "long_shots             0.454402\n",
      "aggression             0.454402\n",
      "interceptions          0.454402\n",
      "positioning            0.454402\n",
      "vision                 1.474633\n",
      "penalties              0.454402\n",
      "marking                0.454402\n",
      "standing_tackle        0.454402\n",
      "sliding_tackle         1.474633\n",
      "gk_diving              0.454402\n",
      "gk_handling            0.454402\n",
      "gk_kicking             0.454402\n",
      "gk_positioning         0.454402\n",
      "gk_reflexes            0.454402\n",
      "dtype: float64\n",
      "id                   0.000000\n",
      "country_id           0.000000\n",
      "league_id            0.000000\n",
      "season               0.000000\n",
      "stage                0.000000\n",
      "date                 0.000000\n",
      "match_api_id         0.000000\n",
      "home_team_api_id     0.000000\n",
      "away_team_api_id     0.000000\n",
      "home_team_goal       0.000000\n",
      "away_team_goal       0.000000\n",
      "home_player_1        4.711498\n",
      "home_player_2        5.061781\n",
      "home_player_3        4.930906\n",
      "home_player_4        5.092575\n",
      "home_player_5        5.065630\n",
      "home_player_6        5.100273\n",
      "home_player_7        4.723046\n",
      "home_player_8        5.038685\n",
      "home_player_9        4.900112\n",
      "home_player_10       5.527541\n",
      "home_player_11       5.985604\n",
      "away_player_1        4.749990\n",
      "away_player_2        4.919358\n",
      "away_player_3        4.977097\n",
      "away_player_4        5.084876\n",
      "away_player_5        5.138766\n",
      "away_player_6        5.054082\n",
      "away_player_7        4.753840\n",
      "away_player_8        5.161862\n",
      "away_player_9        5.111821\n",
      "away_player_10       5.546788\n",
      "away_player_11       5.981754\n",
      "goal                45.275030\n",
      "shoton              45.275030\n",
      "shotoff             45.275030\n",
      "foulcommit          45.275030\n",
      "card                45.275030\n",
      "cross               45.275030\n",
      "corner              45.275030\n",
      "possession          45.275030\n",
      "B365H               13.037453\n",
      "B365D               13.037453\n",
      "B365A               13.037453\n",
      "dtype: float64\n",
      "id            0.0\n",
      "country_id    0.0\n",
      "name          0.0\n",
      "dtype: float64\n",
      "id      0.0\n",
      "name    0.0\n",
      "dtype: float64\n",
      "id                 0.0\n",
      "team_api_id        0.0\n",
      "team_long_name     0.0\n",
      "team_short_name    0.0\n",
      "dtype: float64\n",
      "id                                 0.000000\n",
      "team_api_id                        0.000000\n",
      "date                               0.000000\n",
      "buildUpPlaySpeed                   0.000000\n",
      "buildUpPlaySpeedClass              0.000000\n",
      "buildUpPlayDribbling              66.460905\n",
      "buildUpPlayDribblingClass          0.000000\n",
      "buildUpPlayPassing                 0.000000\n",
      "buildUpPlayPassingClass            0.000000\n",
      "buildUpPlayPositioningClass        0.000000\n",
      "chanceCreationPassing              0.000000\n",
      "chanceCreationPassingClass         0.000000\n",
      "chanceCreationCrossing             0.000000\n",
      "chanceCreationCrossingClass        0.000000\n",
      "chanceCreationShooting             0.000000\n",
      "chanceCreationShooting             0.000000\n",
      "chanceCreationPositioningClass     0.000000\n",
      "defencePressure                    0.000000\n",
      "defencePressureClass               0.000000\n",
      "defenceAggression                  0.000000\n",
      "defenceAggressionClass             0.000000\n",
      "defenceTeamWidth                   0.000000\n",
      "defenceTeamWidthClass              0.000000\n",
      "defenceDefenderLineClass           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cnx = sqlite3.connect('database.sqlite')\n",
    "\n",
    "player_data = pd.read_sql(\"SELECT id, player_api_id, player_name, birthday, height, weight FROM Player\", cnx)\n",
    "player_stats_data = pd.read_sql(\"SELECT id, player_api_id, date, overall_rating, potential, preferred_foot, attacking_work_rate, defensive_work_rate, crossing, finishing, heading_accuracy, short_passing, volleys, dribbling, curve, free_kick_accuracy, long_passing, ball_control, acceleration, sprint_speed, agility, reactions, shot_power, jumping, stamina, strength, long_shots, aggression, interceptions, positioning, vision, penalties, marking, standing_tackle, sliding_tackle, gk_diving, gk_handling, gk_kicking, gk_positioning, gk_reflexes FROM Player_Attributes\", cnx)\n",
    "match_data = pd.read_sql(\"SELECT id, country_id, league_id, season, stage, date, match_api_id, home_team_api_id, away_team_api_id, home_team_goal, away_team_goal, home_player_1, home_player_2, home_player_3, home_player_4, home_player_5, home_player_6, home_player_7, home_player_8, home_player_9, home_player_10, home_player_11, away_player_1, away_player_2, away_player_3, away_player_4, away_player_5, away_player_6, away_player_7, away_player_8, away_player_9, away_player_10, away_player_11, goal, shoton, shotoff, foulcommit, card, cross, corner, possession, B365H, B365D, B365A FROM Match\", cnx)\n",
    "league_data = pd.read_sql(\"SELECT id, country_id, name FROM League\", cnx)\n",
    "country_data = pd.read_sql(\"SELECT id, name FROM Country\", cnx)\n",
    "team_data = pd.read_sql(\"SELECT id, team_api_id, team_long_name, team_short_name FROM Team\", cnx)\n",
    "team_attributes_data = pd.read_sql(\"SELECT id, team_api_id, date, buildUpPlaySpeed, buildUpPlaySpeedClass, buildUpPlayDribbling, buildUpPlayDribblingClass, buildUpPlayPassing, buildUpPlayPassingClass, buildUpPlayPositioningClass, chanceCreationPassing, chanceCreationPassingClass, chanceCreationCrossing, chanceCreationCrossingClass, chanceCreationShooting, chanceCreationShooting, chanceCreationPositioningClass, defencePressure, defencePressureClass, defenceAggression, defenceAggressionClass, defenceTeamWidth, defenceTeamWidthClass, defenceDefenderLineClass FROM Team_Attributes\", cnx)\n",
    "\n",
    "\n",
    "def null_counts( dataframe ):\n",
    "    '''\n",
    "    Get percentage of empty values per column\n",
    "\n",
    "    Args:\n",
    "        dataframe: dataframe containing at least one column and value\n",
    "\n",
    "    Returns:\n",
    "        Returns nothing, prints percentages\n",
    "    '''\n",
    "    null_counts = dataframe.isnull().sum()\n",
    "    null_percents = null_counts / len(dataframe) * 100\n",
    "    print(null_percents)\n",
    "\n",
    "\n",
    "null_counts(player_data)\n",
    "null_counts(player_stats_data)\n",
    "null_counts(match_data)\n",
    "null_counts(league_data)\n",
    "null_counts(country_data)\n",
    "null_counts(team_data)\n",
    "null_counts(team_attributes_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenaufbereitung\n",
    "In diesem Code-Abschnitt werden die Daten bereinigt und für das maschinelle Lernen aufbereitet. Dazu werden die im vorherigen Abschnitt gesammelten Erkenntnisse zu den Anteilen von Leeren Werten je Spalte dazu genutzt, Spalten mit mangelnder Aussagekraft vollständig zu entfernen (`drop()`). Daraufhin wird sich außerdem der verbliebenen leeren Werte in allen Zeilen angenommen.\n",
    "\n",
    "## Spielerratings\n",
    "Die Tabelle Player_Attributes (Dtaframe `player_stats_data`) enthält Spiellerratings für alle Spieler zu verschiedenen Zeitpunkten. Dabei haben manche Spieler mehrere Ratings pro Jahr, andere nur ein Rating pro Jahr, wieder andere nur ein Rating in mehreren Jahren. Um diese unterschiedlichen Vorraussetzungen für alle Spieler auf ein Niveau zu bringen, werden mehrere unterjährige Ratings auf ein einzelnes gemittelt. Im folgenden wird dann für jeden Spieler das Rating aus dem benötigten Jahr verwendet. Gibt es kein Rating aus diesem Jahr, wird das naheliegenste Rating herangezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = match_data.drop(columns=[\"goal\", \"shoton\", \"shotoff\", \"foulcommit\", \"card\", \"cross\", \"corner\", \"possession\"], axis=1)\n",
    "team_attributes_data = team_attributes_data.drop(\"buildUpPlayDribbling\", axis=1)\n",
    "\n",
    "df_dropped = match_data.dropna()\n",
    "player_stats_data = player_stats_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81.9090909090909, 73.44444444444444)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_nearest_rating(date, player_api_id):\n",
    "    '''\n",
    "    Get player rating closest to the provided date\n",
    "\n",
    "    Args:\n",
    "        date: Date as int. (yyyymmdd)\n",
    "        player_api_id: player_api_id as int.\n",
    "\n",
    "    Returns:\n",
    "        Returns a new dataframe containing all player attributes for the nearest date.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: No data for provided player_api_id\n",
    "    '''\n",
    "    all_ratings_for_player: pd.DataFrame = player_stats_data.loc[player_stats_data[\"player_api_id\"] == player_api_id]\n",
    "    if (all_ratings_for_player.empty):\n",
    "        raise ValueError(f\"No data for provided player_api_id: {player_api_id}\")\n",
    "    if (len(all_ratings_for_player.index) == 1):\n",
    "        return all_ratings_for_player\n",
    "    intdate: pd.DataFrame = pd.DataFrame(columns=[\"date\"], dtype=np.int8)\n",
    "    for index, row in all_ratings_for_player.iterrows():\n",
    "        rowdate: str = row[\"date\"][:10]\n",
    "        rowdate = rowdate.replace('-', '')\n",
    "        intdate.loc[index] = int(rowdate)\n",
    "    intdate = intdate.set_index('date')\n",
    "    intdate.sort_index(inplace = True)\n",
    "    index = intdate.index.get_indexer([date], method=\"nearest\")\n",
    "    all_ratings_for_player.reset_index(inplace=True, drop=True)\n",
    "    return all_ratings_for_player.loc[index]\n",
    "\n",
    "def get_average_team_rating(team_api_id, match_api_id):\n",
    "    df_match = match_data.loc[match_data[\"match_api_id\"] == match_api_id]\n",
    "    matchDate: str = df_match[\"date\"].item()\n",
    "    if ((df_match[\"home_team_api_id\"].item() == team_api_id).item()):\n",
    "        df_match = df_match[[\"home_player_1\", \"home_player_2\", \"home_player_3\", \"home_player_4\", \"home_player_5\", \"home_player_6\", \"home_player_7\",\"home_player_8\", \"home_player_9\", \"home_player_10\", \"home_player_11\"]]\n",
    "    elif ((df_match[\"away_team_api_id\"].item() == team_api_id).item()):\n",
    "        df_match = df_match[[\"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\", \"away_player_5\", \"away_player_6\", \"away_player_7\",\"away_player_8\", \"away_player_9\", \"away_player_10\", \"away_player_11\"]] \n",
    "    else:\n",
    "        raise ValueError(\"\") #TODO\n",
    "    \n",
    "    matchDate = matchDate[:10]\n",
    "    matchDate = matchDate.replace('-', '')\n",
    "    matchDateInt: np.int8 = int(matchDate)\n",
    "\n",
    "    teamRating: int = 0\n",
    "    missingPlayers = 0\n",
    "    for name, series in df_match.items():\n",
    "        try:\n",
    "            teamRating = teamRating + get_nearest_rating(date=matchDateInt, player_api_id=int(series.item()))[\"overall_rating\"]\n",
    "        except ValueError:\n",
    "            missingPlayers += 1\n",
    "    \n",
    "    return teamRating / (11 - missingPlayers)\n",
    "\n",
    "def get_match_ratings(match_api_id):\n",
    "    df_match = match_data.loc[match_data[\"match_api_id\"] == match_api_id]\n",
    "    return get_average_team_rating(team_api_id=df_match[\"home_team_api_id\"], match_api_id=match_api_id).item(), get_average_team_rating(team_api_id=df_match[\"away_team_api_id\"], match_api_id=match_api_id).item()\n",
    "\n",
    "get_match_ratings(530240)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Überprüfung ob jeder Spieler aus Match_data auch in der Spielerdatenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "1\n",
      "Int64Index([0], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Select the player columns\n",
    "player_cols = ['home_player_1', 'home_player_2', 'home_player_3', 'home_player_4', 'home_player_5', 'home_player_6', 'home_player_7', 'home_player_8', 'home_player_9', 'home_player_10', 'home_player_11', 'away_player_1', 'away_player_2', 'away_player_3', 'away_player_4', 'away_player_5', 'away_player_6', 'away_player_7', 'away_player_8', 'away_player_9', 'away_player_10', 'away_player_11']\n",
    "    \n",
    "# Combine the columns horizontally\n",
    "combined_players = pd.concat([match_data[col] for col in player_cols])\n",
    "\n",
    "# Remove duplicates\n",
    "unique_players = combined_players.drop_duplicates()\n",
    "print(unique_players[0])\n",
    "\n",
    "# Check if every entry in the Series is in column A of the DataFrame\n",
    "mask = unique_players.isin(player_data['player_api_id'])\n",
    "\n",
    "# Replace the entries not in column A with a specified value\n",
    "unique_players[~mask] = -1\n",
    "\n",
    "# find the indices where the value is -1\n",
    "indices = unique_players.index[unique_players == -1]\n",
    "\n",
    "# count the number of occurrences of each unique value in the series\n",
    "counts = unique_players.value_counts()\n",
    "\n",
    "# print the indices & print the number of occurrences of -1\n",
    "print(counts[-1])\n",
    "print(indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hier muss noch die Zusammenführung der Daten geschehen in ein Dataframe df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrelaitonsmatrix erstellt und in corr_matrix gespeichert => enthält Korrleationskoeffizienten zwischen allen möglichen Paaren\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# stack() wandelt Matrix in Series um, bei der jedes Element ein Paar von Spaltennamen und der Korrelationskoeffizient zwischen diesen Spalten ist\n",
    "# [abs(corr_matrix) > 0.9] reduziert die Werte auf nur Werte mit einem Wert über 0.9\n",
    "high_corr_pairs = corr_matrix.stack()[abs(corr_matrix) > 0.9]\n",
    "\n",
    "# Indizes der Serie werden zu Spaltennamen des Dataframe \n",
    "high_corr_pairs = high_corr_pairs.reset_index()\n",
    "\n",
    "# Spaltennamen des DataFrames umbenannt für bessere Lesbarkeit\n",
    "high_corr_pairs.columns = ['Column 1', 'Column 2', 'Correlation']\n",
    "\n",
    "print(high_corr_pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # erstelle ein Dataframe für die Ergebnis von Chi2\n",
    "chi2_results_df = pd.DataFrame(columns=['Column 1', 'Column 2', 'Chi-Squared', 'P-Value'])\n",
    "\n",
    "# iteriert über jede Spalte des Dataframes\n",
    "for col in df.columns:\n",
    "    comparison_col = col\n",
    "\n",
    "    # iteriert über jede Spalte des Dataframes\n",
    "    for col in df.columns:\n",
    "\n",
    "        # überspringt den Schritt, wenn die Spalten die gleichen sind\n",
    "        if col == comparison_col:\n",
    "            continue\n",
    "\n",
    "        # erstellt eine Kontingenztabelle\n",
    "        contingency_table = pd.crosstab(df[comparison_col], df[col])\n",
    "\n",
    "        # führt chi2 aus und printed das Ergebnis\n",
    "        chi2, pval, dof, expected = chi2_contingency(contingency_table)\n",
    "                    #print(f\\Chi-squared test for columns '{comparison_col}' and '{col}': chi2={chi2}, pval={pval}\\)\n",
    "        results_df = results_df.append({'Column 1': comparison_col, 'Column 2': col, 'Chi-Squared': chi2, 'P-Value': pval}, ignore_index=True)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Was machen wir mit dem Ergebnis\n",
    "\n",
    "#Wrapper Methode\n",
    "Sucht die beste Untergruppe von Features für ein Mdoell, indem eine Modell-basierte Bewertung der Feature-Untergruppen durchführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trennung von Features und Zielvariablen\n",
    "features = df.drop('whoWon', axis=1)\n",
    "target = df['whoWon']\n",
    "\n",
    "# Definition des Modells\n",
    "model = LinearRegression()\n",
    "\n",
    "# Erstellung des RFE-Objekts mit 10 gewünschten Features\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "\n",
    "# Anpassung des RFE-Objekts an die Daten\n",
    "rfe.fit(features, target)\n",
    "\n",
    "# Ausgabe der ausgewählten Features\n",
    "selected_features = features.columns[rfe.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trennung von Features und Zielvariablen\n",
    "features = df.drop('whoWon', axis=1)\n",
    "target = df['whoWon']\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definition des Random-Forest-Modells\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = rf.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Genauigkeit: {accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trennung von Features und Zielvariablen\n",
    "features = df.drop('whoWon', axis=1)\n",
    "target = df['whoWon']\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definition des logistischen Regressionsmodells\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Training des Modells auf den Trainingsdaten\n",
    "lr.fit(features_train, target_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "target_pred = lr.predict(features_test)\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "print(f\"Genauigkeit: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
